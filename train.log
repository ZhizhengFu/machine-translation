2025-06-03 15:24:01,026 INFO: Epoch 0, Batch 0, Loss: 7.4569
2025-06-03 15:24:02,190 INFO: Epoch 0, Batch 50, Loss: 4.7642
2025-06-03 15:24:03,369 INFO: Epoch 0, Batch 100, Loss: 4.5593
2025-06-03 15:24:04,566 INFO: Epoch 0, Batch 150, Loss: 4.2635
2025-06-03 15:24:05,742 INFO: Epoch 0, Batch 200, Loss: 4.1306
2025-06-03 15:24:06,888 INFO: Epoch 0, Batch 250, Loss: 4.0687
2025-06-03 15:24:07,618 INFO: Epoch 0, Train Loss: 4.5098
2025-06-03 15:24:07,673 INFO: Epoch 0, Eval Loss: 3.7950
2025-06-03 15:24:08,802 INFO: New best model saved with loss: 3.7950
2025-06-03 15:24:08,837 INFO: Epoch 1, Batch 0, Loss: 4.0069
2025-06-03 15:24:09,998 INFO: Epoch 1, Batch 50, Loss: 3.6090
2025-06-03 15:24:11,153 INFO: Epoch 1, Batch 100, Loss: 3.8979
2025-06-03 15:24:12,323 INFO: Epoch 1, Batch 150, Loss: 3.6416
2025-06-03 15:24:13,510 INFO: Epoch 1, Batch 200, Loss: 3.7754
2025-06-03 15:24:14,667 INFO: Epoch 1, Batch 250, Loss: 3.5465
2025-06-03 15:24:15,368 INFO: Epoch 1, Train Loss: 3.6193
2025-06-03 15:24:15,415 INFO: Epoch 1, Eval Loss: 3.3152
2025-06-03 15:24:17,040 INFO: New best model saved with loss: 3.3152
2025-06-03 15:24:17,076 INFO: Epoch 2, Batch 0, Loss: 3.4125
2025-06-03 15:24:18,239 INFO: Epoch 2, Batch 50, Loss: 3.4659
2025-06-03 15:24:19,426 INFO: Epoch 2, Batch 100, Loss: 3.3977
2025-06-03 15:24:20,600 INFO: Epoch 2, Batch 150, Loss: 3.1725
2025-06-03 15:24:21,772 INFO: Epoch 2, Batch 200, Loss: 3.1077
2025-06-03 15:24:22,945 INFO: Epoch 2, Batch 250, Loss: 3.2702
2025-06-03 15:24:23,666 INFO: Epoch 2, Train Loss: 3.2241
2025-06-03 15:24:23,713 INFO: Epoch 2, Eval Loss: 3.0799
2025-06-03 15:24:25,214 INFO: New best model saved with loss: 3.0799
2025-06-03 15:24:25,244 INFO: Epoch 3, Batch 0, Loss: 3.0179
2025-06-03 15:24:26,451 INFO: Epoch 3, Batch 50, Loss: 3.2194
2025-06-03 15:24:27,611 INFO: Epoch 3, Batch 100, Loss: 2.9144
2025-06-03 15:24:28,757 INFO: Epoch 3, Batch 150, Loss: 3.0024
2025-06-03 15:24:29,926 INFO: Epoch 3, Batch 200, Loss: 2.6966
2025-06-03 15:24:31,081 INFO: Epoch 3, Batch 250, Loss: 2.8250
2025-06-03 15:24:31,796 INFO: Epoch 3, Train Loss: 2.9392
2025-06-03 15:24:31,843 INFO: Epoch 3, Eval Loss: 2.8567
2025-06-03 15:24:33,105 INFO: New best model saved with loss: 2.8567
2025-06-03 15:24:33,136 INFO: Epoch 4, Batch 0, Loss: 2.7383
2025-06-03 15:24:34,303 INFO: Epoch 4, Batch 50, Loss: 2.7274
2025-06-03 15:24:35,480 INFO: Epoch 4, Batch 100, Loss: 2.6139
2025-06-03 15:24:36,656 INFO: Epoch 4, Batch 150, Loss: 2.6184
2025-06-03 15:24:37,857 INFO: Epoch 4, Batch 200, Loss: 2.7685
2025-06-03 15:24:39,005 INFO: Epoch 4, Batch 250, Loss: 2.7250
2025-06-03 15:24:39,697 INFO: Epoch 4, Train Loss: 2.7163
2025-06-03 15:24:39,746 INFO: Epoch 4, Eval Loss: 2.7308
2025-06-03 15:24:40,991 INFO: New best model saved with loss: 2.7308
2025-06-03 15:24:41,025 INFO: Epoch 5, Batch 0, Loss: 2.2644
2025-06-03 15:24:42,179 INFO: Epoch 5, Batch 50, Loss: 2.4385
2025-06-03 15:24:43,357 INFO: Epoch 5, Batch 100, Loss: 2.5382
2025-06-03 15:24:44,519 INFO: Epoch 5, Batch 150, Loss: 2.7479
2025-06-03 15:24:45,703 INFO: Epoch 5, Batch 200, Loss: 2.6795
2025-06-03 15:24:46,884 INFO: Epoch 5, Batch 250, Loss: 2.5747
2025-06-03 15:24:47,607 INFO: Epoch 5, Train Loss: 2.5368
2025-06-03 15:24:47,655 INFO: Epoch 5, Eval Loss: 2.6607
2025-06-03 15:24:48,919 INFO: New best model saved with loss: 2.6607
2025-06-03 15:24:48,951 INFO: Epoch 6, Batch 0, Loss: 2.3979
2025-06-03 15:24:50,129 INFO: Epoch 6, Batch 50, Loss: 2.3217
2025-06-03 15:24:51,274 INFO: Epoch 6, Batch 100, Loss: 2.3771
2025-06-03 15:24:52,457 INFO: Epoch 6, Batch 150, Loss: 2.4244
2025-06-03 15:24:53,622 INFO: Epoch 6, Batch 200, Loss: 2.2559
2025-06-03 15:24:54,786 INFO: Epoch 6, Batch 250, Loss: 2.4021
2025-06-03 15:24:55,524 INFO: Epoch 6, Train Loss: 2.3784
2025-06-03 15:24:55,572 INFO: Epoch 6, Eval Loss: 2.5795
2025-06-03 15:24:57,020 INFO: New best model saved with loss: 2.5795
2025-06-03 15:24:57,051 INFO: Epoch 7, Batch 0, Loss: 2.3448
2025-06-03 15:24:58,216 INFO: Epoch 7, Batch 50, Loss: 2.2497
2025-06-03 15:24:59,375 INFO: Epoch 7, Batch 100, Loss: 2.2510
2025-06-03 15:25:00,541 INFO: Epoch 7, Batch 150, Loss: 2.2098
2025-06-03 15:25:01,727 INFO: Epoch 7, Batch 200, Loss: 2.1848
2025-06-03 15:25:02,910 INFO: Epoch 7, Batch 250, Loss: 2.1737
2025-06-03 15:25:03,622 INFO: Epoch 7, Train Loss: 2.2451
2025-06-03 15:25:03,670 INFO: Epoch 7, Eval Loss: 2.4877
2025-06-03 15:25:05,695 INFO: New best model saved with loss: 2.4877
2025-06-03 15:25:05,735 INFO: Epoch 8, Batch 0, Loss: 2.2196
2025-06-03 15:25:06,895 INFO: Epoch 8, Batch 50, Loss: 2.2143
2025-06-03 15:25:08,071 INFO: Epoch 8, Batch 100, Loss: 2.0719
2025-06-03 15:25:09,231 INFO: Epoch 8, Batch 150, Loss: 2.1513
2025-06-03 15:25:10,387 INFO: Epoch 8, Batch 200, Loss: 1.9825
2025-06-03 15:25:11,579 INFO: Epoch 8, Batch 250, Loss: 2.0397
2025-06-03 15:25:12,288 INFO: Epoch 8, Train Loss: 2.1213
2025-06-03 15:25:12,336 INFO: Epoch 8, Eval Loss: 2.4327
2025-06-03 15:25:14,357 INFO: New best model saved with loss: 2.4327
2025-06-03 15:25:14,396 INFO: Epoch 9, Batch 0, Loss: 2.1678
2025-06-03 15:25:15,563 INFO: Epoch 9, Batch 50, Loss: 2.0449
2025-06-03 15:25:16,761 INFO: Epoch 9, Batch 100, Loss: 1.9611
2025-06-03 15:25:17,910 INFO: Epoch 9, Batch 150, Loss: 2.0039
2025-06-03 15:25:19,070 INFO: Epoch 9, Batch 200, Loss: 2.2581
2025-06-03 15:25:20,259 INFO: Epoch 9, Batch 250, Loss: 1.9630
2025-06-03 15:25:21,002 INFO: Epoch 9, Train Loss: 2.0083
2025-06-03 15:25:21,066 INFO: Epoch 9, Eval Loss: 2.4085
2025-06-03 15:25:22,939 INFO: New best model saved with loss: 2.4085
2025-06-03 15:25:22,973 INFO: Epoch 10, Batch 0, Loss: 1.8535
2025-06-03 15:25:24,149 INFO: Epoch 10, Batch 50, Loss: 1.9498
2025-06-03 15:25:25,317 INFO: Epoch 10, Batch 100, Loss: 2.0236
2025-06-03 15:25:26,490 INFO: Epoch 10, Batch 150, Loss: 1.9341
2025-06-03 15:25:27,646 INFO: Epoch 10, Batch 200, Loss: 1.9548
2025-06-03 15:25:28,823 INFO: Epoch 10, Batch 250, Loss: 1.8273
2025-06-03 15:25:29,527 INFO: Epoch 10, Train Loss: 1.9082
2025-06-03 15:25:29,575 INFO: Epoch 10, Eval Loss: 2.3492
2025-06-03 15:25:31,588 INFO: New best model saved with loss: 2.3492
2025-06-03 15:25:31,623 INFO: Epoch 11, Batch 0, Loss: 1.8430
2025-06-03 15:25:32,796 INFO: Epoch 11, Batch 50, Loss: 1.8888
2025-06-03 15:25:33,968 INFO: Epoch 11, Batch 100, Loss: 1.8731
2025-06-03 15:25:35,127 INFO: Epoch 11, Batch 150, Loss: 1.7785
2025-06-03 15:25:36,324 INFO: Epoch 11, Batch 200, Loss: 1.8161
2025-06-03 15:25:37,462 INFO: Epoch 11, Batch 250, Loss: 1.8554
2025-06-03 15:25:38,179 INFO: Epoch 11, Train Loss: 1.8145
2025-06-03 15:25:38,227 INFO: Epoch 11, Eval Loss: 2.2879
2025-06-03 15:25:40,543 INFO: New best model saved with loss: 2.2879
2025-06-03 15:25:40,577 INFO: Epoch 12, Batch 0, Loss: 1.5834
2025-06-03 15:25:41,750 INFO: Epoch 12, Batch 50, Loss: 1.8099
2025-06-03 15:25:42,912 INFO: Epoch 12, Batch 100, Loss: 1.6931
2025-06-03 15:25:44,111 INFO: Epoch 12, Batch 150, Loss: 1.8615
2025-06-03 15:25:45,263 INFO: Epoch 12, Batch 200, Loss: 1.5809
2025-06-03 15:25:46,432 INFO: Epoch 12, Batch 250, Loss: 1.9515
2025-06-03 15:25:47,134 INFO: Epoch 12, Train Loss: 1.7263
2025-06-03 15:25:47,181 INFO: Epoch 12, Eval Loss: 2.3539
2025-06-03 15:25:47,203 INFO: Epoch 13, Batch 0, Loss: 1.6878
2025-06-03 15:25:48,372 INFO: Epoch 13, Batch 50, Loss: 1.7901
2025-06-03 15:25:49,561 INFO: Epoch 13, Batch 100, Loss: 1.5838
2025-06-03 15:25:50,720 INFO: Epoch 13, Batch 150, Loss: 1.6146
2025-06-03 15:25:51,880 INFO: Epoch 13, Batch 200, Loss: 1.5540
2025-06-03 15:25:53,043 INFO: Epoch 13, Batch 250, Loss: 1.7370
2025-06-03 15:25:53,767 INFO: Epoch 13, Train Loss: 1.6503
2025-06-03 15:25:53,813 INFO: Epoch 13, Eval Loss: 2.2931
2025-06-03 15:25:53,842 INFO: Epoch 14, Batch 0, Loss: 1.6049
2025-06-03 15:25:54,993 INFO: Epoch 14, Batch 50, Loss: 1.4183
2025-06-03 15:25:56,159 INFO: Epoch 14, Batch 100, Loss: 1.6345
2025-06-03 15:25:57,336 INFO: Epoch 14, Batch 150, Loss: 1.4019
2025-06-03 15:25:58,509 INFO: Epoch 14, Batch 200, Loss: 1.6233
2025-06-03 15:25:59,696 INFO: Epoch 14, Batch 250, Loss: 1.6729
2025-06-03 15:26:00,428 INFO: Epoch 14, Train Loss: 1.5707
2025-06-03 15:26:00,477 INFO: Epoch 14, Eval Loss: 2.2554
2025-06-03 15:26:02,524 INFO: New best model saved with loss: 2.2554
2025-06-03 15:26:02,555 INFO: Epoch 15, Batch 0, Loss: 1.4548
2025-06-03 15:26:03,733 INFO: Epoch 15, Batch 50, Loss: 1.4023
2025-06-03 15:26:04,939 INFO: Epoch 15, Batch 100, Loss: 1.5286
2025-06-03 15:26:06,105 INFO: Epoch 15, Batch 150, Loss: 1.4404
2025-06-03 15:26:07,257 INFO: Epoch 15, Batch 200, Loss: 1.5620
2025-06-03 15:26:08,409 INFO: Epoch 15, Batch 250, Loss: 1.7041
2025-06-03 15:26:09,111 INFO: Epoch 15, Train Loss: 1.4961
2025-06-03 15:26:09,160 INFO: Epoch 15, Eval Loss: 2.2198
2025-06-03 15:26:11,084 INFO: New best model saved with loss: 2.2198
2025-06-03 15:26:11,120 INFO: Epoch 16, Batch 0, Loss: 1.4305
2025-06-03 15:26:12,268 INFO: Epoch 16, Batch 50, Loss: 1.3001
2025-06-03 15:26:13,438 INFO: Epoch 16, Batch 100, Loss: 1.3915
2025-06-03 15:26:14,624 INFO: Epoch 16, Batch 150, Loss: 1.3866
2025-06-03 15:26:15,806 INFO: Epoch 16, Batch 200, Loss: 1.3835
2025-06-03 15:26:16,991 INFO: Epoch 16, Batch 250, Loss: 1.4813
2025-06-03 15:26:17,692 INFO: Epoch 16, Train Loss: 1.4306
2025-06-03 15:26:17,740 INFO: Epoch 16, Eval Loss: 2.2152
2025-06-03 15:26:19,611 INFO: New best model saved with loss: 2.2152
2025-06-03 15:26:19,644 INFO: Epoch 17, Batch 0, Loss: 1.1394
2025-06-03 15:26:20,846 INFO: Epoch 17, Batch 50, Loss: 1.5583
2025-06-03 15:26:22,015 INFO: Epoch 17, Batch 100, Loss: 1.3127
2025-06-03 15:26:23,175 INFO: Epoch 17, Batch 150, Loss: 1.3861
2025-06-03 15:26:24,337 INFO: Epoch 17, Batch 200, Loss: 1.2950
2025-06-03 15:26:25,497 INFO: Epoch 17, Batch 250, Loss: 1.5364
2025-06-03 15:26:26,211 INFO: Epoch 17, Train Loss: 1.3667
2025-06-03 15:26:26,259 INFO: Epoch 17, Eval Loss: 2.2238
2025-06-03 15:26:26,283 INFO: Epoch 18, Batch 0, Loss: 1.3498
2025-06-03 15:26:27,447 INFO: Epoch 18, Batch 50, Loss: 1.3015
2025-06-03 15:26:28,614 INFO: Epoch 18, Batch 100, Loss: 1.2591
2025-06-03 15:26:29,770 INFO: Epoch 18, Batch 150, Loss: 1.2459
2025-06-03 15:26:30,943 INFO: Epoch 18, Batch 200, Loss: 1.3176
2025-06-03 15:26:32,128 INFO: Epoch 18, Batch 250, Loss: 1.2191
2025-06-03 15:26:32,854 INFO: Epoch 18, Train Loss: 1.3077
2025-06-03 15:26:32,902 INFO: Epoch 18, Eval Loss: 2.1884
2025-06-03 15:26:34,915 INFO: New best model saved with loss: 2.1884
2025-06-03 15:26:34,949 INFO: Epoch 19, Batch 0, Loss: 1.1276
2025-06-03 15:26:36,113 INFO: Epoch 19, Batch 50, Loss: 1.1935
2025-06-03 15:26:37,271 INFO: Epoch 19, Batch 100, Loss: 1.1494
2025-06-03 15:26:38,442 INFO: Epoch 19, Batch 150, Loss: 1.1329
2025-06-03 15:26:39,595 INFO: Epoch 19, Batch 200, Loss: 1.2151
2025-06-03 15:26:40,769 INFO: Epoch 19, Batch 250, Loss: 1.3271
2025-06-03 15:26:41,493 INFO: Epoch 19, Train Loss: 1.2492
2025-06-03 15:26:41,540 INFO: Epoch 19, Eval Loss: 2.2049
2025-06-03 15:26:41,566 INFO: Epoch 20, Batch 0, Loss: 1.1536
2025-06-03 15:26:42,728 INFO: Epoch 20, Batch 50, Loss: 1.0925
2025-06-03 15:26:43,903 INFO: Epoch 20, Batch 100, Loss: 1.3602
2025-06-03 15:26:45,057 INFO: Epoch 20, Batch 150, Loss: 1.2066
2025-06-03 15:26:46,255 INFO: Epoch 20, Batch 200, Loss: 1.2372
2025-06-03 15:26:47,439 INFO: Epoch 20, Batch 250, Loss: 1.2076
2025-06-03 15:26:48,131 INFO: Epoch 20, Train Loss: 1.1921
2025-06-03 15:26:48,179 INFO: Epoch 20, Eval Loss: 2.1537
2025-06-03 15:26:50,112 INFO: New best model saved with loss: 2.1537
2025-06-03 15:26:50,150 INFO: Epoch 21, Batch 0, Loss: 0.9649
2025-06-03 15:26:51,305 INFO: Epoch 21, Batch 50, Loss: 1.2121
2025-06-03 15:26:52,484 INFO: Epoch 21, Batch 100, Loss: 1.0661
2025-06-03 15:26:53,655 INFO: Epoch 21, Batch 150, Loss: 1.2077
2025-06-03 15:26:54,831 INFO: Epoch 21, Batch 200, Loss: 1.1037
2025-06-03 15:26:56,002 INFO: Epoch 21, Batch 250, Loss: 1.1683
2025-06-03 15:26:56,714 INFO: Epoch 21, Train Loss: 1.1406
2025-06-03 15:26:56,762 INFO: Epoch 21, Eval Loss: 2.1597
2025-06-03 15:26:56,787 INFO: Epoch 22, Batch 0, Loss: 1.0778
2025-06-03 15:26:57,957 INFO: Epoch 22, Batch 50, Loss: 1.1289
2025-06-03 15:26:59,118 INFO: Epoch 22, Batch 100, Loss: 1.2021
2025-06-03 15:27:00,298 INFO: Epoch 22, Batch 150, Loss: 1.1837
2025-06-03 15:27:01,471 INFO: Epoch 22, Batch 200, Loss: 1.1160
2025-06-03 15:27:02,639 INFO: Epoch 22, Batch 250, Loss: 1.0900
2025-06-03 15:27:03,355 INFO: Epoch 22, Train Loss: 1.0893
2025-06-03 15:27:03,402 INFO: Epoch 22, Eval Loss: 2.1241
2025-06-03 15:27:05,301 INFO: New best model saved with loss: 2.1241
2025-06-03 15:27:05,329 INFO: Epoch 23, Batch 0, Loss: 1.0168
2025-06-03 15:27:06,483 INFO: Epoch 23, Batch 50, Loss: 1.0832
2025-06-03 15:27:07,674 INFO: Epoch 23, Batch 100, Loss: 0.9722
2025-06-03 15:27:08,833 INFO: Epoch 23, Batch 150, Loss: 1.0002
2025-06-03 15:27:10,001 INFO: Epoch 23, Batch 200, Loss: 1.1151
2025-06-03 15:27:11,163 INFO: Epoch 23, Batch 250, Loss: 1.1058
2025-06-03 15:27:11,885 INFO: Epoch 23, Train Loss: 1.0435
2025-06-03 15:27:11,933 INFO: Epoch 23, Eval Loss: 2.0950
2025-06-03 15:27:13,875 INFO: New best model saved with loss: 2.0950
2025-06-03 15:27:13,910 INFO: Epoch 24, Batch 0, Loss: 0.8175
2025-06-03 15:27:15,078 INFO: Epoch 24, Batch 50, Loss: 0.9377
2025-06-03 15:27:16,220 INFO: Epoch 24, Batch 100, Loss: 1.0803
2025-06-03 15:27:17,410 INFO: Epoch 24, Batch 150, Loss: 1.0165
2025-06-03 15:27:18,577 INFO: Epoch 24, Batch 200, Loss: 0.9369
2025-06-03 15:27:19,752 INFO: Epoch 24, Batch 250, Loss: 0.9281
2025-06-03 15:27:20,470 INFO: Epoch 24, Train Loss: 0.9963
2025-06-03 15:27:20,518 INFO: Epoch 24, Eval Loss: 2.0775
2025-06-03 15:27:22,554 INFO: New best model saved with loss: 2.0775
2025-06-03 15:27:22,583 INFO: Epoch 25, Batch 0, Loss: 0.9199
2025-06-03 15:27:23,735 INFO: Epoch 25, Batch 50, Loss: 0.8734
2025-06-03 15:27:24,898 INFO: Epoch 25, Batch 100, Loss: 0.9467
2025-06-03 15:27:26,044 INFO: Epoch 25, Batch 150, Loss: 0.9429
2025-06-03 15:27:27,235 INFO: Epoch 25, Batch 200, Loss: 1.0031
2025-06-03 15:27:28,409 INFO: Epoch 25, Batch 250, Loss: 1.0854
2025-06-03 15:27:29,128 INFO: Epoch 25, Train Loss: 0.9541
2025-06-03 15:27:29,176 INFO: Epoch 25, Eval Loss: 2.1153
2025-06-03 15:27:29,200 INFO: Epoch 26, Batch 0, Loss: 0.7617
2025-06-03 15:27:30,371 INFO: Epoch 26, Batch 50, Loss: 0.8557
2025-06-03 15:27:31,550 INFO: Epoch 26, Batch 100, Loss: 0.7869
2025-06-03 15:27:32,705 INFO: Epoch 26, Batch 150, Loss: 0.8640
2025-06-03 15:27:33,877 INFO: Epoch 26, Batch 200, Loss: 0.9336
2025-06-03 15:27:35,049 INFO: Epoch 26, Batch 250, Loss: 1.0011
2025-06-03 15:27:35,767 INFO: Epoch 26, Train Loss: 0.9100
2025-06-03 15:27:35,815 INFO: Epoch 26, Eval Loss: 2.0106
2025-06-03 15:27:37,880 INFO: New best model saved with loss: 2.0106
2025-06-03 15:27:37,914 INFO: Epoch 27, Batch 0, Loss: 0.8818
2025-06-03 15:27:39,072 INFO: Epoch 27, Batch 50, Loss: 0.7821
2025-06-03 15:27:40,245 INFO: Epoch 27, Batch 100, Loss: 0.8310
2025-06-03 15:27:41,430 INFO: Epoch 27, Batch 150, Loss: 0.9388
2025-06-03 15:27:42,613 INFO: Epoch 27, Batch 200, Loss: 0.9131
2025-06-03 15:27:43,776 INFO: Epoch 27, Batch 250, Loss: 0.8188
2025-06-03 15:27:44,496 INFO: Epoch 27, Train Loss: 0.8725
2025-06-03 15:27:44,543 INFO: Epoch 27, Eval Loss: 2.0408
2025-06-03 15:27:44,566 INFO: Epoch 28, Batch 0, Loss: 0.7272
2025-06-03 15:27:45,731 INFO: Epoch 28, Batch 50, Loss: 0.7928
2025-06-03 15:27:46,880 INFO: Epoch 28, Batch 100, Loss: 0.7960
2025-06-03 15:27:48,064 INFO: Epoch 28, Batch 150, Loss: 0.9212
2025-06-03 15:27:49,228 INFO: Epoch 28, Batch 200, Loss: 0.8418
2025-06-03 15:27:50,420 INFO: Epoch 28, Batch 250, Loss: 0.8713
2025-06-03 15:27:51,122 INFO: Epoch 28, Train Loss: 0.8351
2025-06-03 15:27:51,170 INFO: Epoch 28, Eval Loss: 2.0768
2025-06-03 15:27:51,194 INFO: Epoch 29, Batch 0, Loss: 0.6699
2025-06-03 15:27:52,364 INFO: Epoch 29, Batch 50, Loss: 0.7386
2025-06-03 15:27:53,550 INFO: Epoch 29, Batch 100, Loss: 0.8552
2025-06-03 15:27:54,693 INFO: Epoch 29, Batch 150, Loss: 0.9198
2025-06-03 15:27:55,872 INFO: Epoch 29, Batch 200, Loss: 0.7893
2025-06-03 15:27:57,060 INFO: Epoch 29, Batch 250, Loss: 0.7823
2025-06-03 15:27:57,790 INFO: Epoch 29, Train Loss: 0.7994
2025-06-03 15:27:57,839 INFO: Epoch 29, Eval Loss: 2.0432
2025-06-03 15:27:57,861 INFO: Epoch 30, Batch 0, Loss: 0.7660
2025-06-03 15:27:59,037 INFO: Epoch 30, Batch 50, Loss: 0.7704
2025-06-03 15:28:00,184 INFO: Epoch 30, Batch 100, Loss: 0.7379
2025-06-03 15:28:01,354 INFO: Epoch 30, Batch 150, Loss: 0.7560
2025-06-03 15:28:02,542 INFO: Epoch 30, Batch 200, Loss: 0.7876
2025-06-03 15:28:03,720 INFO: Epoch 30, Batch 250, Loss: 0.7094
2025-06-03 15:28:04,444 INFO: Epoch 30, Train Loss: 0.7666
2025-06-03 15:28:04,492 INFO: Epoch 30, Eval Loss: 2.0262
2025-06-03 15:28:04,518 INFO: Epoch 31, Batch 0, Loss: 0.6685
2025-06-03 15:28:05,691 INFO: Epoch 31, Batch 50, Loss: 0.6644
2025-06-03 15:28:06,852 INFO: Epoch 31, Batch 100, Loss: 0.6444
2025-06-03 15:28:08,043 INFO: Epoch 31, Batch 150, Loss: 0.6197
2025-06-03 15:28:09,217 INFO: Epoch 31, Batch 200, Loss: 0.6675
2025-06-03 15:28:10,380 INFO: Epoch 31, Batch 250, Loss: 0.6776
2025-06-03 15:28:11,099 INFO: Epoch 31, Train Loss: 0.6700
2025-06-03 15:28:11,147 INFO: Epoch 31, Eval Loss: 1.9825
2025-06-03 15:28:13,281 INFO: New best model saved with loss: 1.9825
2025-06-03 15:28:13,317 INFO: Epoch 32, Batch 0, Loss: 0.7586
2025-06-03 15:28:14,482 INFO: Epoch 32, Batch 50, Loss: 0.6013
2025-06-03 15:28:15,643 INFO: Epoch 32, Batch 100, Loss: 0.5861
2025-06-03 15:28:16,830 INFO: Epoch 32, Batch 150, Loss: 0.6700
2025-06-03 15:28:17,986 INFO: Epoch 32, Batch 200, Loss: 0.6326
2025-06-03 15:28:19,168 INFO: Epoch 32, Batch 250, Loss: 0.6562
2025-06-03 15:28:19,888 INFO: Epoch 32, Train Loss: 0.6331
2025-06-03 15:28:19,935 INFO: Epoch 32, Eval Loss: 1.9933
2025-06-03 15:28:19,957 INFO: Epoch 33, Batch 0, Loss: 0.6177
2025-06-03 15:28:21,117 INFO: Epoch 33, Batch 50, Loss: 0.6352
2025-06-03 15:28:22,277 INFO: Epoch 33, Batch 100, Loss: 0.5884
2025-06-03 15:28:23,463 INFO: Epoch 33, Batch 150, Loss: 0.6243
2025-06-03 15:28:24,632 INFO: Epoch 33, Batch 200, Loss: 0.6290
2025-06-03 15:28:25,802 INFO: Epoch 33, Batch 250, Loss: 0.6551
2025-06-03 15:28:26,519 INFO: Epoch 33, Train Loss: 0.6124
2025-06-03 15:28:26,567 INFO: Epoch 33, Eval Loss: 1.9691
2025-06-03 15:28:28,520 INFO: New best model saved with loss: 1.9691
2025-06-03 15:28:28,554 INFO: Epoch 34, Batch 0, Loss: 0.5440
2025-06-03 15:28:29,711 INFO: Epoch 34, Batch 50, Loss: 0.5715
2025-06-03 15:28:30,878 INFO: Epoch 34, Batch 100, Loss: 0.5871
2025-06-03 15:28:32,046 INFO: Epoch 34, Batch 150, Loss: 0.6508
2025-06-03 15:28:33,225 INFO: Epoch 34, Batch 200, Loss: 0.5479
2025-06-03 15:28:34,371 INFO: Epoch 34, Batch 250, Loss: 0.5921
2025-06-03 15:28:35,092 INFO: Epoch 34, Train Loss: 0.5958
2025-06-03 15:28:35,140 INFO: Epoch 34, Eval Loss: 1.9604
2025-06-03 15:28:36,952 INFO: New best model saved with loss: 1.9604
2025-06-03 15:28:36,981 INFO: Epoch 35, Batch 0, Loss: 0.5543
2025-06-03 15:28:38,145 INFO: Epoch 35, Batch 50, Loss: 0.5006
2025-06-03 15:28:39,316 INFO: Epoch 35, Batch 100, Loss: 0.5854
2025-06-03 15:28:40,506 INFO: Epoch 35, Batch 150, Loss: 0.5749
2025-06-03 15:28:41,691 INFO: Epoch 35, Batch 200, Loss: 0.5414
2025-06-03 15:28:42,881 INFO: Epoch 35, Batch 250, Loss: 0.5596
2025-06-03 15:28:43,610 INFO: Epoch 35, Train Loss: 0.5774
2025-06-03 15:28:43,659 INFO: Epoch 35, Eval Loss: 1.9372
2025-06-03 15:28:44,952 INFO: New best model saved with loss: 1.9372
2025-06-03 15:28:44,983 INFO: Epoch 36, Batch 0, Loss: 0.5015
2025-06-03 15:28:46,163 INFO: Epoch 36, Batch 50, Loss: 0.5492
2025-06-03 15:28:47,362 INFO: Epoch 36, Batch 100, Loss: 0.5391
2025-06-03 15:28:48,534 INFO: Epoch 36, Batch 150, Loss: 0.5537
2025-06-03 15:28:49,699 INFO: Epoch 36, Batch 200, Loss: 0.5907
2025-06-03 15:28:50,880 INFO: Epoch 36, Batch 250, Loss: 0.5523
2025-06-03 15:28:51,593 INFO: Epoch 36, Train Loss: 0.5598
2025-06-03 15:28:51,641 INFO: Epoch 36, Eval Loss: 1.9411
2025-06-03 15:28:51,665 INFO: Epoch 37, Batch 0, Loss: 0.5556
2025-06-03 15:28:52,834 INFO: Epoch 37, Batch 50, Loss: 0.5850
2025-06-03 15:28:54,017 INFO: Epoch 37, Batch 100, Loss: 0.5535
2025-06-03 15:28:55,172 INFO: Epoch 37, Batch 150, Loss: 0.4925
2025-06-03 15:28:56,352 INFO: Epoch 37, Batch 200, Loss: 0.5071
2025-06-03 15:28:57,538 INFO: Epoch 37, Batch 250, Loss: 0.6111
2025-06-03 15:28:58,272 INFO: Epoch 37, Train Loss: 0.5443
2025-06-03 15:28:58,318 INFO: Epoch 37, Eval Loss: 1.9527
2025-06-03 15:28:58,343 INFO: Epoch 38, Batch 0, Loss: 0.5389
2025-06-03 15:28:59,510 INFO: Epoch 38, Batch 50, Loss: 0.5892
2025-06-03 15:29:00,676 INFO: Epoch 38, Batch 100, Loss: 0.4871
2025-06-03 15:29:01,863 INFO: Epoch 38, Batch 150, Loss: 0.5207
2025-06-03 15:29:03,052 INFO: Epoch 38, Batch 200, Loss: 0.5549
2025-06-03 15:29:04,203 INFO: Epoch 38, Batch 250, Loss: 0.5716
2025-06-03 15:29:04,926 INFO: Epoch 38, Train Loss: 0.5314
2025-06-03 15:29:04,973 INFO: Epoch 38, Eval Loss: 1.9532
2025-06-03 15:29:04,997 INFO: Epoch 39, Batch 0, Loss: 0.5305
2025-06-03 15:29:06,173 INFO: Epoch 39, Batch 50, Loss: 0.5163
2025-06-03 15:29:07,339 INFO: Epoch 39, Batch 100, Loss: 0.4938
2025-06-03 15:29:08,509 INFO: Epoch 39, Batch 150, Loss: 0.5021
2025-06-03 15:29:09,665 INFO: Epoch 39, Batch 200, Loss: 0.5298
2025-06-03 15:29:10,842 INFO: Epoch 39, Batch 250, Loss: 0.5604
2025-06-03 15:29:11,555 INFO: Epoch 39, Train Loss: 0.5160
2025-06-03 15:29:11,602 INFO: Epoch 39, Eval Loss: 1.9420
2025-06-03 15:29:11,627 INFO: Epoch 40, Batch 0, Loss: 0.4797
2025-06-03 15:29:12,791 INFO: Epoch 40, Batch 50, Loss: 0.4911
2025-06-03 15:29:13,980 INFO: Epoch 40, Batch 100, Loss: 0.4492
2025-06-03 15:29:15,142 INFO: Epoch 40, Batch 150, Loss: 0.4049
2025-06-03 15:29:16,322 INFO: Epoch 40, Batch 200, Loss: 0.4867
2025-06-03 15:29:17,484 INFO: Epoch 40, Batch 250, Loss: 0.5007
2025-06-03 15:29:18,211 INFO: Epoch 40, Train Loss: 0.4771
2025-06-03 15:29:18,258 INFO: Epoch 40, Eval Loss: 1.9548
2025-06-03 15:29:18,285 INFO: Epoch 41, Batch 0, Loss: 0.4826
2025-06-03 15:29:19,451 INFO: Epoch 41, Batch 50, Loss: 0.5104
2025-06-03 15:29:20,641 INFO: Epoch 41, Batch 100, Loss: 0.4704
2025-06-03 15:29:21,821 INFO: Epoch 41, Batch 150, Loss: 0.4646
2025-06-03 15:29:23,002 INFO: Epoch 41, Batch 200, Loss: 0.4454
2025-06-03 15:29:24,172 INFO: Epoch 41, Batch 250, Loss: 0.4288
2025-06-03 15:29:24,897 INFO: Epoch 41, Train Loss: 0.4615
2025-06-03 15:29:24,945 INFO: Epoch 41, Eval Loss: 1.9361
2025-06-03 15:29:26,211 INFO: New best model saved with loss: 1.9361
2025-06-03 15:29:26,247 INFO: Epoch 42, Batch 0, Loss: 0.4704
2025-06-03 15:29:27,409 INFO: Epoch 42, Batch 50, Loss: 0.4125
2025-06-03 15:29:28,571 INFO: Epoch 42, Batch 100, Loss: 0.4249
2025-06-03 15:29:29,748 INFO: Epoch 42, Batch 150, Loss: 0.4266
2025-06-03 15:29:30,920 INFO: Epoch 42, Batch 200, Loss: 0.4447
2025-06-03 15:29:32,078 INFO: Epoch 42, Batch 250, Loss: 0.4861
2025-06-03 15:29:32,812 INFO: Epoch 42, Train Loss: 0.4567
2025-06-03 15:29:32,860 INFO: Epoch 42, Eval Loss: 1.9401
2025-06-03 15:29:32,883 INFO: Epoch 43, Batch 0, Loss: 0.4343
2025-06-03 15:29:34,060 INFO: Epoch 43, Batch 50, Loss: 0.4697
2025-06-03 15:29:35,238 INFO: Epoch 43, Batch 100, Loss: 0.4761
2025-06-03 15:29:36,407 INFO: Epoch 43, Batch 150, Loss: 0.4517
2025-06-03 15:29:37,567 INFO: Epoch 43, Batch 200, Loss: 0.4669
2025-06-03 15:29:38,750 INFO: Epoch 43, Batch 250, Loss: 0.4359
2025-06-03 15:29:39,465 INFO: Epoch 43, Train Loss: 0.4466
2025-06-03 15:29:39,514 INFO: Epoch 43, Eval Loss: 1.9328
2025-06-03 15:29:40,907 INFO: New best model saved with loss: 1.9328
2025-06-03 15:29:40,945 INFO: Epoch 44, Batch 0, Loss: 0.4399
2025-06-03 15:29:42,125 INFO: Epoch 44, Batch 50, Loss: 0.4383
2025-06-03 15:29:43,298 INFO: Epoch 44, Batch 100, Loss: 0.3980
2025-06-03 15:29:44,474 INFO: Epoch 44, Batch 150, Loss: 0.4403
2025-06-03 15:29:45,649 INFO: Epoch 44, Batch 200, Loss: 0.4776
2025-06-03 15:29:46,813 INFO: Epoch 44, Batch 250, Loss: 0.5239
2025-06-03 15:29:47,528 INFO: Epoch 44, Train Loss: 0.4379
2025-06-03 15:29:47,577 INFO: Epoch 44, Eval Loss: 1.9151
2025-06-03 15:29:48,824 INFO: New best model saved with loss: 1.9151
2025-06-03 15:29:48,858 INFO: Epoch 45, Batch 0, Loss: 0.4335
2025-06-03 15:29:50,057 INFO: Epoch 45, Batch 50, Loss: 0.3744
2025-06-03 15:29:51,233 INFO: Epoch 45, Batch 100, Loss: 0.4461
2025-06-03 15:29:52,404 INFO: Epoch 45, Batch 150, Loss: 0.4231
2025-06-03 15:29:53,570 INFO: Epoch 45, Batch 200, Loss: 0.4535
2025-06-03 15:29:54,748 INFO: Epoch 45, Batch 250, Loss: 0.4589
2025-06-03 15:29:55,465 INFO: Epoch 45, Train Loss: 0.4319
2025-06-03 15:29:55,515 INFO: Epoch 45, Eval Loss: 1.9219
2025-06-03 15:29:55,539 INFO: Epoch 46, Batch 0, Loss: 0.4386
2025-06-03 15:29:56,712 INFO: Epoch 46, Batch 50, Loss: 0.3998
2025-06-03 15:29:57,867 INFO: Epoch 46, Batch 100, Loss: 0.4636
2025-06-03 15:29:59,035 INFO: Epoch 46, Batch 150, Loss: 0.4045
2025-06-03 15:30:00,203 INFO: Epoch 46, Batch 200, Loss: 0.4261
2025-06-03 15:30:01,381 INFO: Epoch 46, Batch 250, Loss: 0.4378
2025-06-03 15:30:02,092 INFO: Epoch 46, Train Loss: 0.4237
2025-06-03 15:30:02,140 INFO: Epoch 46, Eval Loss: 1.9149
2025-06-03 15:30:03,496 INFO: New best model saved with loss: 1.9149
2025-06-03 15:30:03,529 INFO: Epoch 47, Batch 0, Loss: 0.4127
2025-06-03 15:30:04,693 INFO: Epoch 47, Batch 50, Loss: 0.4160
2025-06-03 15:30:05,872 INFO: Epoch 47, Batch 100, Loss: 0.3808
2025-06-03 15:30:07,040 INFO: Epoch 47, Batch 150, Loss: 0.4242
2025-06-03 15:30:08,207 INFO: Epoch 47, Batch 200, Loss: 0.4255
2025-06-03 15:30:09,362 INFO: Epoch 47, Batch 250, Loss: 0.3554
2025-06-03 15:30:10,075 INFO: Epoch 47, Train Loss: 0.4184
2025-06-03 15:30:10,123 INFO: Epoch 47, Eval Loss: 1.9053
2025-06-03 15:30:11,815 INFO: New best model saved with loss: 1.9053
2025-06-03 15:30:11,899 INFO: Epoch 48, Batch 0, Loss: 0.3696
2025-06-03 15:30:13,062 INFO: Epoch 48, Batch 50, Loss: 0.3982
2025-06-03 15:30:14,239 INFO: Epoch 48, Batch 100, Loss: 0.4005
2025-06-03 15:30:15,436 INFO: Epoch 48, Batch 150, Loss: 0.3923
2025-06-03 15:30:16,602 INFO: Epoch 48, Batch 200, Loss: 0.4136
2025-06-03 15:30:17,794 INFO: Epoch 48, Batch 250, Loss: 0.4076
2025-06-03 15:30:18,493 INFO: Epoch 48, Train Loss: 0.4111
2025-06-03 15:30:18,541 INFO: Epoch 48, Eval Loss: 1.9200
2025-06-03 15:30:18,564 INFO: Epoch 49, Batch 0, Loss: 0.3682
2025-06-03 15:30:19,729 INFO: Epoch 49, Batch 50, Loss: 0.3737
2025-06-03 15:30:20,901 INFO: Epoch 49, Batch 100, Loss: 0.3984
2025-06-03 15:30:22,083 INFO: Epoch 49, Batch 150, Loss: 0.3956
2025-06-03 15:30:23,280 INFO: Epoch 49, Batch 200, Loss: 0.4432
2025-06-03 15:30:24,433 INFO: Epoch 49, Batch 250, Loss: 0.3906
2025-06-03 15:30:25,128 INFO: Epoch 49, Train Loss: 0.4068
2025-06-03 15:30:25,175 INFO: Epoch 49, Eval Loss: 1.9312
2025-06-03 15:30:25,200 INFO: Epoch 50, Batch 0, Loss: 0.3943
2025-06-03 15:30:26,359 INFO: Epoch 50, Batch 50, Loss: 0.3969
2025-06-03 15:30:27,516 INFO: Epoch 50, Batch 100, Loss: 0.4111
2025-06-03 15:30:28,687 INFO: Epoch 50, Batch 150, Loss: 0.3824
2025-06-03 15:30:29,871 INFO: Epoch 50, Batch 200, Loss: 0.4241
2025-06-03 15:30:31,050 INFO: Epoch 50, Batch 250, Loss: 0.4116
2025-06-03 15:30:31,764 INFO: Epoch 50, Train Loss: 0.4019
2025-06-03 15:30:31,811 INFO: Epoch 50, Eval Loss: 1.9133
2025-06-03 15:30:31,835 INFO: Epoch 51, Batch 0, Loss: 0.3622
2025-06-03 15:30:33,009 INFO: Epoch 51, Batch 50, Loss: 0.3574
2025-06-03 15:30:34,173 INFO: Epoch 51, Batch 100, Loss: 0.4117
2025-06-03 15:30:35,334 INFO: Epoch 51, Batch 150, Loss: 0.3839
2025-06-03 15:30:36,492 INFO: Epoch 51, Batch 200, Loss: 0.4229
2025-06-03 15:30:37,654 INFO: Epoch 51, Batch 250, Loss: 0.3649
2025-06-03 15:30:38,368 INFO: Epoch 51, Train Loss: 0.3963
2025-06-03 15:30:38,415 INFO: Epoch 51, Eval Loss: 1.9211
2025-06-03 15:30:38,439 INFO: Epoch 52, Batch 0, Loss: 0.4909
2025-06-03 15:30:39,626 INFO: Epoch 52, Batch 50, Loss: 0.3896
2025-06-03 15:30:40,800 INFO: Epoch 52, Batch 100, Loss: 0.3210
2025-06-03 15:30:41,968 INFO: Epoch 52, Batch 150, Loss: 0.3774
2025-06-03 15:30:43,153 INFO: Epoch 52, Batch 200, Loss: 0.3483
2025-06-03 15:30:44,299 INFO: Epoch 52, Batch 250, Loss: 0.3701
2025-06-03 15:30:45,020 INFO: Epoch 52, Train Loss: 0.3808
2025-06-03 15:30:45,068 INFO: Epoch 52, Eval Loss: 1.9184
2025-06-03 15:30:45,094 INFO: Epoch 53, Batch 0, Loss: 0.3620
2025-06-03 15:30:46,273 INFO: Epoch 53, Batch 50, Loss: 0.3671
2025-06-03 15:30:47,447 INFO: Epoch 53, Batch 100, Loss: 0.3641
2025-06-03 15:30:48,599 INFO: Epoch 53, Batch 150, Loss: 0.3771
2025-06-03 15:30:49,757 INFO: Epoch 53, Batch 200, Loss: 0.3685
2025-06-03 15:30:50,953 INFO: Epoch 53, Batch 250, Loss: 0.3759
2025-06-03 15:30:51,661 INFO: Epoch 53, Train Loss: 0.3743
2025-06-03 15:30:51,707 INFO: Epoch 53, Eval Loss: 1.9025
2025-06-03 15:30:53,879 INFO: New best model saved with loss: 1.9025
2025-06-03 15:30:53,912 INFO: Epoch 54, Batch 0, Loss: 0.3614
2025-06-03 15:30:55,081 INFO: Epoch 54, Batch 50, Loss: 0.3998
2025-06-03 15:30:56,248 INFO: Epoch 54, Batch 100, Loss: 0.3213
2025-06-03 15:30:57,386 INFO: Epoch 54, Batch 150, Loss: 0.3870
2025-06-03 15:30:58,553 INFO: Epoch 54, Batch 200, Loss: 0.3846
2025-06-03 15:30:59,748 INFO: Epoch 54, Batch 250, Loss: 0.3911
2025-06-03 15:31:00,452 INFO: Epoch 54, Train Loss: 0.3715
2025-06-03 15:31:00,499 INFO: Epoch 54, Eval Loss: 1.9041
2025-06-03 15:31:00,522 INFO: Epoch 55, Batch 0, Loss: 0.3838
2025-06-03 15:31:01,701 INFO: Epoch 55, Batch 50, Loss: 0.3721
2025-06-03 15:31:02,864 INFO: Epoch 55, Batch 100, Loss: 0.3530
2025-06-03 15:31:04,026 INFO: Epoch 55, Batch 150, Loss: 0.3514
2025-06-03 15:31:05,201 INFO: Epoch 55, Batch 200, Loss: 0.3674
2025-06-03 15:31:06,364 INFO: Epoch 55, Batch 250, Loss: 0.3577
2025-06-03 15:31:07,076 INFO: Epoch 55, Train Loss: 0.3680
2025-06-03 15:31:07,123 INFO: Epoch 55, Eval Loss: 1.9129
2025-06-03 15:31:07,145 INFO: Epoch 56, Batch 0, Loss: 0.3802
2025-06-03 15:31:08,346 INFO: Epoch 56, Batch 50, Loss: 0.3941
2025-06-03 15:31:09,477 INFO: Epoch 56, Batch 100, Loss: 0.3733
2025-06-03 15:31:10,635 INFO: Epoch 56, Batch 150, Loss: 0.3826
2025-06-03 15:31:11,784 INFO: Epoch 56, Batch 200, Loss: 0.3646
2025-06-03 15:31:12,957 INFO: Epoch 56, Batch 250, Loss: 0.3657
2025-06-03 15:31:13,671 INFO: Epoch 56, Train Loss: 0.3659
2025-06-03 15:31:13,717 INFO: Epoch 56, Eval Loss: 1.9047
2025-06-03 15:31:13,744 INFO: Epoch 57, Batch 0, Loss: 0.3542
2025-06-03 15:31:14,931 INFO: Epoch 57, Batch 50, Loss: 0.3266
2025-06-03 15:31:16,101 INFO: Epoch 57, Batch 100, Loss: 0.3691
2025-06-03 15:31:17,271 INFO: Epoch 57, Batch 150, Loss: 0.3708
2025-06-03 15:31:18,430 INFO: Epoch 57, Batch 200, Loss: 0.3630
2025-06-03 15:31:19,586 INFO: Epoch 57, Batch 250, Loss: 0.3767
2025-06-03 15:31:20,303 INFO: Epoch 57, Train Loss: 0.3614
2025-06-03 15:31:20,350 INFO: Epoch 57, Eval Loss: 1.9002
2025-06-03 15:31:22,408 INFO: New best model saved with loss: 1.9002
2025-06-03 15:31:22,441 INFO: Epoch 58, Batch 0, Loss: 0.3304
2025-06-03 15:31:23,599 INFO: Epoch 58, Batch 50, Loss: 0.3359
2025-06-03 15:31:24,780 INFO: Epoch 58, Batch 100, Loss: 0.3521
2025-06-03 15:31:25,943 INFO: Epoch 58, Batch 150, Loss: 0.3508
2025-06-03 15:31:27,117 INFO: Epoch 58, Batch 200, Loss: 0.3574
2025-06-03 15:31:28,275 INFO: Epoch 58, Batch 250, Loss: 0.3525
2025-06-03 15:31:28,983 INFO: Epoch 58, Train Loss: 0.3597
2025-06-03 15:31:29,032 INFO: Epoch 58, Eval Loss: 1.9030
2025-06-03 15:31:29,063 INFO: Epoch 59, Batch 0, Loss: 0.3309
2025-06-03 15:31:30,249 INFO: Epoch 59, Batch 50, Loss: 0.3464
2025-06-03 15:31:31,417 INFO: Epoch 59, Batch 100, Loss: 0.3373
2025-06-03 15:31:32,609 INFO: Epoch 59, Batch 150, Loss: 0.3468
2025-06-03 15:31:33,769 INFO: Epoch 59, Batch 200, Loss: 0.3672
2025-06-03 15:31:34,941 INFO: Epoch 59, Batch 250, Loss: 0.3855
2025-06-03 15:31:35,663 INFO: Epoch 59, Train Loss: 0.3563
2025-06-03 15:31:35,711 INFO: Epoch 59, Eval Loss: 1.9035
2025-06-03 15:31:35,738 INFO: Epoch 60, Batch 0, Loss: 0.3603
2025-06-03 15:31:36,921 INFO: Epoch 60, Batch 50, Loss: 0.3970
2025-06-03 15:31:38,089 INFO: Epoch 60, Batch 100, Loss: 0.3488
2025-06-03 15:31:39,241 INFO: Epoch 60, Batch 150, Loss: 0.3403
2025-06-03 15:31:40,431 INFO: Epoch 60, Batch 200, Loss: 0.3785
2025-06-03 15:31:41,600 INFO: Epoch 60, Batch 250, Loss: 0.3655
2025-06-03 15:31:42,298 INFO: Epoch 60, Train Loss: 0.3534
2025-06-03 15:31:42,346 INFO: Epoch 60, Eval Loss: 1.9038
2025-06-03 15:31:42,367 INFO: Epoch 61, Batch 0, Loss: 0.3362
2025-06-03 15:31:43,515 INFO: Epoch 61, Batch 50, Loss: 0.3623
2025-06-03 15:31:44,712 INFO: Epoch 61, Batch 100, Loss: 0.3861
2025-06-03 15:31:45,866 INFO: Epoch 61, Batch 150, Loss: 0.3336
2025-06-03 15:31:47,049 INFO: Epoch 61, Batch 200, Loss: 0.3493
2025-06-03 15:31:48,207 INFO: Epoch 61, Batch 250, Loss: 0.3656
2025-06-03 15:31:48,911 INFO: Epoch 61, Train Loss: 0.3506
2025-06-03 15:31:48,959 INFO: Epoch 61, Eval Loss: 1.9023
2025-06-03 15:31:48,985 INFO: Epoch 62, Batch 0, Loss: 0.3675
2025-06-03 15:31:50,139 INFO: Epoch 62, Batch 50, Loss: 0.3569
2025-06-03 15:31:51,325 INFO: Epoch 62, Batch 100, Loss: 0.3808
2025-06-03 15:31:52,497 INFO: Epoch 62, Batch 150, Loss: 0.3398
2025-06-03 15:31:53,666 INFO: Epoch 62, Batch 200, Loss: 0.3394
2025-06-03 15:31:54,850 INFO: Epoch 62, Batch 250, Loss: 0.3403
2025-06-03 15:31:55,568 INFO: Epoch 62, Train Loss: 0.3448
2025-06-03 15:31:55,615 INFO: Epoch 62, Eval Loss: 1.9010
2025-06-03 15:31:55,642 INFO: Epoch 63, Batch 0, Loss: 0.3388
2025-06-03 15:31:56,822 INFO: Epoch 63, Batch 50, Loss: 0.3474
2025-06-03 15:31:58,001 INFO: Epoch 63, Batch 100, Loss: 0.3306
2025-06-03 15:31:59,168 INFO: Epoch 63, Batch 150, Loss: 0.3401
2025-06-03 15:32:00,329 INFO: Epoch 63, Batch 200, Loss: 0.3599
2025-06-03 15:32:01,484 INFO: Epoch 63, Batch 250, Loss: 0.3603
2025-06-03 15:32:02,194 INFO: Epoch 63, Train Loss: 0.3412
2025-06-03 15:32:02,242 INFO: Epoch 63, Eval Loss: 1.9009
2025-06-03 15:32:02,269 INFO: Epoch 64, Batch 0, Loss: 0.3240
2025-06-03 15:32:03,442 INFO: Epoch 64, Batch 50, Loss: 0.3291
2025-06-03 15:32:04,624 INFO: Epoch 64, Batch 100, Loss: 0.3023
2025-06-03 15:32:05,792 INFO: Epoch 64, Batch 150, Loss: 0.3423
2025-06-03 15:32:06,944 INFO: Epoch 64, Batch 200, Loss: 0.3442
2025-06-03 15:32:08,119 INFO: Epoch 64, Batch 250, Loss: 0.3593
2025-06-03 15:32:08,831 INFO: Epoch 64, Train Loss: 0.3406
2025-06-03 15:32:08,878 INFO: Epoch 64, Eval Loss: 1.8967
2025-06-03 15:32:11,016 INFO: New best model saved with loss: 1.8967
2025-06-03 15:32:11,049 INFO: Epoch 65, Batch 0, Loss: 0.3291
2025-06-03 15:32:12,231 INFO: Epoch 65, Batch 50, Loss: 0.3358
2025-06-03 15:32:13,397 INFO: Epoch 65, Batch 100, Loss: 0.3437
2025-06-03 15:32:14,590 INFO: Epoch 65, Batch 150, Loss: 0.3285
2025-06-03 15:32:15,778 INFO: Epoch 65, Batch 200, Loss: 0.3617
2025-06-03 15:32:16,945 INFO: Epoch 65, Batch 250, Loss: 0.3069
2025-06-03 15:32:17,649 INFO: Epoch 65, Train Loss: 0.3379
2025-06-03 15:32:17,696 INFO: Epoch 65, Eval Loss: 1.8977
2025-06-03 15:32:17,720 INFO: Epoch 66, Batch 0, Loss: 0.3531
2025-06-03 15:32:18,887 INFO: Epoch 66, Batch 50, Loss: 0.3424
2025-06-03 15:32:20,053 INFO: Epoch 66, Batch 100, Loss: 0.3156
2025-06-03 15:32:21,232 INFO: Epoch 66, Batch 150, Loss: 0.3411
2025-06-03 15:32:22,441 INFO: Epoch 66, Batch 200, Loss: 0.3235
2025-06-03 15:32:23,598 INFO: Epoch 66, Batch 250, Loss: 0.3208
2025-06-03 15:32:24,307 INFO: Epoch 66, Train Loss: 0.3381
2025-06-03 15:32:24,355 INFO: Epoch 66, Eval Loss: 1.8961
2025-06-03 15:32:26,456 INFO: New best model saved with loss: 1.8961
2025-06-03 15:32:26,493 INFO: Epoch 67, Batch 0, Loss: 0.3278
2025-06-03 15:32:27,648 INFO: Epoch 67, Batch 50, Loss: 0.3354
2025-06-03 15:32:28,825 INFO: Epoch 67, Batch 100, Loss: 0.3378
2025-06-03 15:32:30,004 INFO: Epoch 67, Batch 150, Loss: 0.3324
2025-06-03 15:32:31,189 INFO: Epoch 67, Batch 200, Loss: 0.3286
2025-06-03 15:32:32,359 INFO: Epoch 67, Batch 250, Loss: 0.3672
2025-06-03 15:32:33,072 INFO: Epoch 67, Train Loss: 0.3358
2025-06-03 15:32:33,120 INFO: Epoch 67, Eval Loss: 1.8976
2025-06-03 15:32:33,146 INFO: Epoch 68, Batch 0, Loss: 0.3398
2025-06-03 15:32:34,298 INFO: Epoch 68, Batch 50, Loss: 0.3432
2025-06-03 15:32:35,463 INFO: Epoch 68, Batch 100, Loss: 0.3182
2025-06-03 15:32:36,638 INFO: Epoch 68, Batch 150, Loss: 0.3659
2025-06-03 15:32:37,794 INFO: Epoch 68, Batch 200, Loss: 0.3221
2025-06-03 15:32:38,988 INFO: Epoch 68, Batch 250, Loss: 0.3058
2025-06-03 15:32:39,691 INFO: Epoch 68, Train Loss: 0.3342
2025-06-03 15:32:39,740 INFO: Epoch 68, Eval Loss: 1.8961
2025-06-03 15:32:41,797 INFO: New best model saved with loss: 1.8961
2025-06-03 15:32:41,829 INFO: Epoch 69, Batch 0, Loss: 0.3439
2025-06-03 15:32:42,999 INFO: Epoch 69, Batch 50, Loss: 0.3361
2025-06-03 15:32:44,166 INFO: Epoch 69, Batch 100, Loss: 0.3488
2025-06-03 15:32:45,357 INFO: Epoch 69, Batch 150, Loss: 0.3546
2025-06-03 15:32:46,523 INFO: Epoch 69, Batch 200, Loss: 0.3575
2025-06-03 15:32:47,705 INFO: Epoch 69, Batch 250, Loss: 0.3325
2025-06-03 15:32:48,415 INFO: Epoch 69, Train Loss: 0.3329
2025-06-03 15:32:48,463 INFO: Epoch 69, Eval Loss: 1.9010
2025-06-03 15:32:48,487 INFO: Epoch 70, Batch 0, Loss: 0.3150
2025-06-03 15:32:49,658 INFO: Epoch 70, Batch 50, Loss: 0.3277
2025-06-03 15:32:50,826 INFO: Epoch 70, Batch 100, Loss: 0.3306
2025-06-03 15:32:51,987 INFO: Epoch 70, Batch 150, Loss: 0.3229
2025-06-03 15:32:53,150 INFO: Epoch 70, Batch 200, Loss: 0.3068
2025-06-03 15:32:54,314 INFO: Epoch 70, Batch 250, Loss: 0.3664
2025-06-03 15:32:55,042 INFO: Epoch 70, Train Loss: 0.3315
2025-06-03 15:32:55,090 INFO: Epoch 70, Eval Loss: 1.8995
2025-06-03 15:32:55,109 INFO: Epoch 71, Batch 0, Loss: 0.3107
2025-06-03 15:32:56,252 INFO: Epoch 71, Batch 50, Loss: 0.3479
2025-06-03 15:32:57,419 INFO: Epoch 71, Batch 100, Loss: 0.3608
2025-06-03 15:32:58,601 INFO: Epoch 71, Batch 150, Loss: 0.3505
2025-06-03 15:32:59,773 INFO: Epoch 71, Batch 200, Loss: 0.3859
2025-06-03 15:33:00,943 INFO: Epoch 71, Batch 250, Loss: 0.3126
2025-06-03 15:33:01,658 INFO: Epoch 71, Train Loss: 0.3284
2025-06-03 15:33:01,706 INFO: Epoch 71, Eval Loss: 1.8963
2025-06-03 15:33:01,730 INFO: Epoch 72, Batch 0, Loss: 0.3020
2025-06-03 15:33:02,881 INFO: Epoch 72, Batch 50, Loss: 0.3649
2025-06-03 15:33:04,070 INFO: Epoch 72, Batch 100, Loss: 0.3241
2025-06-03 15:33:05,244 INFO: Epoch 72, Batch 150, Loss: 0.3303
2025-06-03 15:33:06,422 INFO: Epoch 72, Batch 200, Loss: 0.3179
2025-06-03 15:33:07,575 INFO: Epoch 72, Batch 250, Loss: 0.3354
2025-06-03 15:33:08,286 INFO: Epoch 72, Train Loss: 0.3278
2025-06-03 15:33:08,334 INFO: Epoch 72, Eval Loss: 1.9005
2025-06-03 15:33:08,357 INFO: Epoch 73, Batch 0, Loss: 0.3149
2025-06-03 15:33:09,542 INFO: Epoch 73, Batch 50, Loss: 0.3291
2025-06-03 15:33:10,712 INFO: Epoch 73, Batch 100, Loss: 0.3285
2025-06-03 15:33:11,877 INFO: Epoch 73, Batch 150, Loss: 0.2996
2025-06-03 15:33:13,049 INFO: Epoch 73, Batch 200, Loss: 0.3476
2025-06-03 15:33:14,223 INFO: Epoch 73, Batch 250, Loss: 0.3549
2025-06-03 15:33:14,962 INFO: Epoch 73, Train Loss: 0.3255
2025-06-03 15:33:15,011 INFO: Epoch 73, Eval Loss: 1.8969
2025-06-03 15:33:15,038 INFO: Epoch 74, Batch 0, Loss: 0.3333
2025-06-03 15:33:16,204 INFO: Epoch 74, Batch 50, Loss: 0.3317
2025-06-03 15:33:17,378 INFO: Epoch 74, Batch 100, Loss: 0.2928
2025-06-03 15:33:18,562 INFO: Epoch 74, Batch 150, Loss: 0.3470
2025-06-03 15:33:19,733 INFO: Epoch 74, Batch 200, Loss: 0.3443
2025-06-03 15:33:20,930 INFO: Epoch 74, Batch 250, Loss: 0.3606
2025-06-03 15:33:21,649 INFO: Epoch 74, Train Loss: 0.3251
2025-06-03 15:33:21,698 INFO: Epoch 74, Eval Loss: 1.8986
2025-06-03 15:33:21,725 INFO: Epoch 75, Batch 0, Loss: 0.3073
2025-06-03 15:33:22,892 INFO: Epoch 75, Batch 50, Loss: 0.3081
2025-06-03 15:33:24,071 INFO: Epoch 75, Batch 100, Loss: 0.2875
2025-06-03 15:33:25,255 INFO: Epoch 75, Batch 150, Loss: 0.3504
2025-06-03 15:33:26,441 INFO: Epoch 75, Batch 200, Loss: 0.3213
2025-06-03 15:33:27,601 INFO: Epoch 75, Batch 250, Loss: 0.2998
2025-06-03 15:33:28,326 INFO: Epoch 75, Train Loss: 0.3238
2025-06-03 15:33:28,374 INFO: Epoch 75, Eval Loss: 1.8965
2025-06-03 15:33:28,396 INFO: Epoch 76, Batch 0, Loss: 0.2808
2025-06-03 15:33:29,570 INFO: Epoch 76, Batch 50, Loss: 0.3440
2025-06-03 15:33:30,759 INFO: Epoch 76, Batch 100, Loss: 0.3718
2025-06-03 15:33:31,955 INFO: Epoch 76, Batch 150, Loss: 0.3167
2025-06-03 15:33:33,117 INFO: Epoch 76, Batch 200, Loss: 0.3297
2025-06-03 15:33:34,300 INFO: Epoch 76, Batch 250, Loss: 0.3265
2025-06-03 15:33:35,034 INFO: Epoch 76, Train Loss: 0.3238
2025-06-03 15:33:35,082 INFO: Epoch 76, Eval Loss: 1.8995
2025-06-03 15:33:35,106 INFO: Epoch 77, Batch 0, Loss: 0.3571
2025-06-03 15:33:36,265 INFO: Epoch 77, Batch 50, Loss: 0.3045
2025-06-03 15:33:37,460 INFO: Epoch 77, Batch 100, Loss: 0.2976
2025-06-03 15:33:38,634 INFO: Epoch 77, Batch 150, Loss: 0.3280
2025-06-03 15:33:39,805 INFO: Epoch 77, Batch 200, Loss: 0.3369
2025-06-03 15:33:40,979 INFO: Epoch 77, Batch 250, Loss: 0.2934
2025-06-03 15:33:41,693 INFO: Epoch 77, Train Loss: 0.3234
2025-06-03 15:33:41,739 INFO: Epoch 77, Eval Loss: 1.8974
2025-06-03 15:33:41,762 INFO: Epoch 78, Batch 0, Loss: 0.3184
2025-06-03 15:33:42,929 INFO: Epoch 78, Batch 50, Loss: 0.3158
2025-06-03 15:33:44,102 INFO: Epoch 78, Batch 100, Loss: 0.3439
2025-06-03 15:33:45,301 INFO: Epoch 78, Batch 150, Loss: 0.3184
2025-06-03 15:33:46,487 INFO: Epoch 78, Batch 200, Loss: 0.3185
2025-06-03 15:33:47,675 INFO: Epoch 78, Batch 250, Loss: 0.3206
2025-06-03 15:33:48,394 INFO: Epoch 78, Train Loss: 0.3227
2025-06-03 15:33:48,442 INFO: Epoch 78, Eval Loss: 1.8960
2025-06-03 15:33:49,856 INFO: New best model saved with loss: 1.8960
2025-06-03 15:33:49,890 INFO: Epoch 79, Batch 0, Loss: 0.2930
2025-06-03 15:33:51,076 INFO: Epoch 79, Batch 50, Loss: 0.3416
2025-06-03 15:33:52,281 INFO: Epoch 79, Batch 100, Loss: 0.3392
2025-06-03 15:33:53,468 INFO: Epoch 79, Batch 150, Loss: 0.2807
2025-06-03 15:33:54,641 INFO: Epoch 79, Batch 200, Loss: 0.3326
2025-06-03 15:33:55,813 INFO: Epoch 79, Batch 250, Loss: 0.3255
2025-06-03 15:33:56,530 INFO: Epoch 79, Train Loss: 0.3221
2025-06-03 15:33:56,579 INFO: Epoch 79, Eval Loss: 1.8952
2025-06-03 15:33:57,825 INFO: New best model saved with loss: 1.8952
2025-06-03 15:33:57,859 INFO: Epoch 80, Batch 0, Loss: 0.3458
2025-06-03 15:33:59,023 INFO: Epoch 80, Batch 50, Loss: 0.3185
2025-06-03 15:34:00,214 INFO: Epoch 80, Batch 100, Loss: 0.3189
2025-06-03 15:34:01,396 INFO: Epoch 80, Batch 150, Loss: 0.3359
2025-06-03 15:34:02,594 INFO: Epoch 80, Batch 200, Loss: 0.3240
2025-06-03 15:34:03,771 INFO: Epoch 80, Batch 250, Loss: 0.3096
2025-06-03 15:34:04,489 INFO: Epoch 80, Train Loss: 0.3220
2025-06-03 15:34:04,537 INFO: Epoch 80, Eval Loss: 1.8958
2025-06-03 15:34:04,561 INFO: Epoch 81, Batch 0, Loss: 0.3243
2025-06-03 15:34:05,723 INFO: Epoch 81, Batch 50, Loss: 0.2961
2025-06-03 15:34:06,930 INFO: Epoch 81, Batch 100, Loss: 0.3556
2025-06-03 15:34:08,111 INFO: Epoch 81, Batch 150, Loss: 0.2980
2025-06-03 15:34:09,295 INFO: Epoch 81, Batch 200, Loss: 0.2945
2025-06-03 15:34:10,493 INFO: Epoch 81, Batch 250, Loss: 0.3093
2025-06-03 15:34:11,229 INFO: Epoch 81, Train Loss: 0.3212
2025-06-03 15:34:11,277 INFO: Epoch 81, Eval Loss: 1.8980
2025-06-03 15:34:11,300 INFO: Epoch 82, Batch 0, Loss: 0.3393
2025-06-03 15:34:12,481 INFO: Epoch 82, Batch 50, Loss: 0.3284
2025-06-03 15:34:13,680 INFO: Epoch 82, Batch 100, Loss: 0.2848
2025-06-03 15:34:14,869 INFO: Epoch 82, Batch 150, Loss: 0.3009
2025-06-03 15:34:16,065 INFO: Epoch 82, Batch 200, Loss: 0.2945
2025-06-03 15:34:17,255 INFO: Epoch 82, Batch 250, Loss: 0.2931
2025-06-03 15:34:17,985 INFO: Epoch 82, Train Loss: 0.3221
2025-06-03 15:34:18,033 INFO: Epoch 82, Eval Loss: 1.8989
2025-06-03 15:34:18,057 INFO: Epoch 83, Batch 0, Loss: 0.3237
2025-06-03 15:34:19,231 INFO: Epoch 83, Batch 50, Loss: 0.2998
2025-06-03 15:34:20,402 INFO: Epoch 83, Batch 100, Loss: 0.2892
2025-06-03 15:34:21,596 INFO: Epoch 83, Batch 150, Loss: 0.3248
2025-06-03 15:34:22,784 INFO: Epoch 83, Batch 200, Loss: 0.3026
2025-06-03 15:34:23,969 INFO: Epoch 83, Batch 250, Loss: 0.2770
2025-06-03 15:34:24,688 INFO: Epoch 83, Train Loss: 0.3211
2025-06-03 15:34:24,736 INFO: Epoch 83, Eval Loss: 1.8969
2025-06-03 15:34:24,758 INFO: Epoch 84, Batch 0, Loss: 0.3040
2025-06-03 15:34:25,928 INFO: Epoch 84, Batch 50, Loss: 0.3307
2025-06-03 15:34:27,101 INFO: Epoch 84, Batch 100, Loss: 0.2935
2025-06-03 15:34:28,306 INFO: Epoch 84, Batch 150, Loss: 0.3127
2025-06-03 15:34:29,488 INFO: Epoch 84, Batch 200, Loss: 0.3152
2025-06-03 15:34:30,674 INFO: Epoch 84, Batch 250, Loss: 0.3504
2025-06-03 15:34:31,390 INFO: Epoch 84, Train Loss: 0.3192
2025-06-03 15:34:31,439 INFO: Epoch 84, Eval Loss: 1.8965
2025-06-03 15:34:31,465 INFO: Epoch 85, Batch 0, Loss: 0.3402
2025-06-03 15:34:32,626 INFO: Epoch 85, Batch 50, Loss: 0.3711
2025-06-03 15:34:33,804 INFO: Epoch 85, Batch 100, Loss: 0.2803
2025-06-03 15:34:35,005 INFO: Epoch 85, Batch 150, Loss: 0.3097
2025-06-03 15:34:36,184 INFO: Epoch 85, Batch 200, Loss: 0.2966
2025-06-03 15:34:37,366 INFO: Epoch 85, Batch 250, Loss: 0.3372
2025-06-03 15:34:38,095 INFO: Epoch 85, Train Loss: 0.3214
2025-06-03 15:34:38,143 INFO: Epoch 85, Eval Loss: 1.8975
2025-06-03 15:34:38,165 INFO: Epoch 86, Batch 0, Loss: 0.3181
2025-06-03 15:34:39,361 INFO: Epoch 86, Batch 50, Loss: 0.3098
2025-06-03 15:34:40,533 INFO: Epoch 86, Batch 100, Loss: 0.3037
2025-06-03 15:34:41,734 INFO: Epoch 86, Batch 150, Loss: 0.3311
2025-06-03 15:34:42,926 INFO: Epoch 86, Batch 200, Loss: 0.3530
2025-06-03 15:34:44,104 INFO: Epoch 86, Batch 250, Loss: 0.3544
2025-06-03 15:34:44,815 INFO: Epoch 86, Train Loss: 0.3204
2025-06-03 15:34:44,864 INFO: Epoch 86, Eval Loss: 1.8965
2025-06-03 15:34:44,892 INFO: Epoch 87, Batch 0, Loss: 0.3745
2025-06-03 15:34:46,101 INFO: Epoch 87, Batch 50, Loss: 0.3262
2025-06-03 15:34:47,280 INFO: Epoch 87, Batch 100, Loss: 0.2886
2025-06-03 15:34:48,436 INFO: Epoch 87, Batch 150, Loss: 0.2914
2025-06-03 15:34:49,635 INFO: Epoch 87, Batch 200, Loss: 0.3488
2025-06-03 15:34:50,824 INFO: Epoch 87, Batch 250, Loss: 0.3365
2025-06-03 15:34:51,529 INFO: Epoch 87, Train Loss: 0.3200
2025-06-03 15:34:51,576 INFO: Epoch 87, Eval Loss: 1.8955
2025-06-03 15:34:51,601 INFO: Epoch 88, Batch 0, Loss: 0.3581
2025-06-03 15:34:52,766 INFO: Epoch 88, Batch 50, Loss: 0.2901
2025-06-03 15:34:53,953 INFO: Epoch 88, Batch 100, Loss: 0.3484
2025-06-03 15:34:55,131 INFO: Epoch 88, Batch 150, Loss: 0.3157
2025-06-03 15:34:56,317 INFO: Epoch 88, Batch 200, Loss: 0.3052
2025-06-03 15:34:57,515 INFO: Epoch 88, Batch 250, Loss: 0.3284
2025-06-03 15:34:58,239 INFO: Epoch 88, Train Loss: 0.3198
2025-06-03 15:34:58,288 INFO: Epoch 88, Eval Loss: 1.8962
2025-06-03 15:34:58,310 INFO: Epoch 89, Batch 0, Loss: 0.3076
2025-06-03 15:34:59,498 INFO: Epoch 89, Batch 50, Loss: 0.3431
2025-06-03 15:35:00,689 INFO: Epoch 89, Batch 100, Loss: 0.3540
2025-06-03 15:35:01,852 INFO: Epoch 89, Batch 150, Loss: 0.2805
2025-06-03 15:35:03,044 INFO: Epoch 89, Batch 200, Loss: 0.3172
2025-06-03 15:35:04,247 INFO: Epoch 89, Batch 250, Loss: 0.3124
2025-06-03 15:35:04,963 INFO: Epoch 89, Train Loss: 0.3196
2025-06-03 15:35:05,011 INFO: Epoch 89, Eval Loss: 1.8958
2025-06-03 15:35:05,033 INFO: Epoch 90, Batch 0, Loss: 0.3419
2025-06-03 15:35:06,221 INFO: Epoch 90, Batch 50, Loss: 0.3378
2025-06-03 15:35:07,397 INFO: Epoch 90, Batch 100, Loss: 0.3441
2025-06-03 15:35:08,606 INFO: Epoch 90, Batch 150, Loss: 0.3101
2025-06-03 15:35:09,787 INFO: Epoch 90, Batch 200, Loss: 0.3084
2025-06-03 15:35:10,966 INFO: Epoch 90, Batch 250, Loss: 0.2938
2025-06-03 15:35:11,707 INFO: Epoch 90, Train Loss: 0.3199
2025-06-03 15:35:11,754 INFO: Epoch 90, Eval Loss: 1.8960
2025-06-03 15:35:11,777 INFO: Epoch 91, Batch 0, Loss: 0.3493
2025-06-03 15:35:12,974 INFO: Epoch 91, Batch 50, Loss: 0.3150
2025-06-03 15:35:14,144 INFO: Epoch 91, Batch 100, Loss: 0.3319
2025-06-03 15:35:15,311 INFO: Epoch 91, Batch 150, Loss: 0.3162
2025-06-03 15:35:16,503 INFO: Epoch 91, Batch 200, Loss: 0.2992
2025-06-03 15:35:17,702 INFO: Epoch 91, Batch 250, Loss: 0.3207
2025-06-03 15:35:18,425 INFO: Epoch 91, Train Loss: 0.3197
2025-06-03 15:35:18,473 INFO: Epoch 91, Eval Loss: 1.8961
2025-06-03 15:35:18,496 INFO: Epoch 92, Batch 0, Loss: 0.3323
2025-06-03 15:35:19,667 INFO: Epoch 92, Batch 50, Loss: 0.3157
2025-06-03 15:35:20,850 INFO: Epoch 92, Batch 100, Loss: 0.3175
2025-06-03 15:35:22,020 INFO: Epoch 92, Batch 150, Loss: 0.3292
2025-06-03 15:35:23,236 INFO: Epoch 92, Batch 200, Loss: 0.2930
2025-06-03 15:35:24,405 INFO: Epoch 92, Batch 250, Loss: 0.3079
2025-06-03 15:35:25,119 INFO: Epoch 92, Train Loss: 0.3208
2025-06-03 15:35:25,167 INFO: Epoch 92, Eval Loss: 1.8955
2025-06-03 15:35:25,192 INFO: Epoch 93, Batch 0, Loss: 0.2981
2025-06-03 15:35:26,371 INFO: Epoch 93, Batch 50, Loss: 0.2943
2025-06-03 15:35:27,578 INFO: Epoch 93, Batch 100, Loss: 0.3229
2025-06-03 15:35:28,765 INFO: Epoch 93, Batch 150, Loss: 0.3257
2025-06-03 15:35:29,940 INFO: Epoch 93, Batch 200, Loss: 0.3357
2025-06-03 15:35:31,123 INFO: Epoch 93, Batch 250, Loss: 0.3845
2025-06-03 15:35:31,853 INFO: Epoch 93, Train Loss: 0.3199
2025-06-03 15:35:31,901 INFO: Epoch 93, Eval Loss: 1.8956
2025-06-03 15:35:31,925 INFO: Epoch 94, Batch 0, Loss: 0.3626
2025-06-03 15:35:33,115 INFO: Epoch 94, Batch 50, Loss: 0.3302
2025-06-03 15:35:34,324 INFO: Epoch 94, Batch 100, Loss: 0.3137
2025-06-03 15:35:35,523 INFO: Epoch 94, Batch 150, Loss: 0.3141
2025-06-03 15:35:36,680 INFO: Epoch 94, Batch 200, Loss: 0.3433
2025-06-03 15:35:37,852 INFO: Epoch 94, Batch 250, Loss: 0.3146
2025-06-03 15:35:38,577 INFO: Epoch 94, Train Loss: 0.3201
2025-06-03 15:35:38,625 INFO: Epoch 94, Eval Loss: 1.8958
2025-06-03 15:35:38,651 INFO: Epoch 95, Batch 0, Loss: 0.3505
2025-06-03 15:35:39,844 INFO: Epoch 95, Batch 50, Loss: 0.3381
2025-06-03 15:35:41,044 INFO: Epoch 95, Batch 100, Loss: 0.3180
2025-06-03 15:35:42,214 INFO: Epoch 95, Batch 150, Loss: 0.3007
2025-06-03 15:35:43,388 INFO: Epoch 95, Batch 200, Loss: 0.3091
2025-06-03 15:35:44,589 INFO: Epoch 95, Batch 250, Loss: 0.3229
2025-06-03 15:35:45,311 INFO: Epoch 95, Train Loss: 0.3194
2025-06-03 15:35:45,359 INFO: Epoch 95, Eval Loss: 1.8959
2025-06-03 15:35:45,385 INFO: Epoch 96, Batch 0, Loss: 0.3576
2025-06-03 15:35:46,563 INFO: Epoch 96, Batch 50, Loss: 0.3283
2025-06-03 15:35:47,744 INFO: Epoch 96, Batch 100, Loss: 0.2950
2025-06-03 15:35:48,915 INFO: Epoch 96, Batch 150, Loss: 0.3052
2025-06-03 15:35:50,125 INFO: Epoch 96, Batch 200, Loss: 0.3223
2025-06-03 15:35:51,307 INFO: Epoch 96, Batch 250, Loss: 0.3071
2025-06-03 15:35:52,049 INFO: Epoch 96, Train Loss: 0.3187
2025-06-03 15:35:52,098 INFO: Epoch 96, Eval Loss: 1.8958
2025-06-03 15:35:52,122 INFO: Epoch 97, Batch 0, Loss: 0.2940
2025-06-03 15:35:53,334 INFO: Epoch 97, Batch 50, Loss: 0.3249
2025-06-03 15:35:54,506 INFO: Epoch 97, Batch 100, Loss: 0.3205
2025-06-03 15:35:55,686 INFO: Epoch 97, Batch 150, Loss: 0.2884
2025-06-03 15:35:56,858 INFO: Epoch 97, Batch 200, Loss: 0.3454
2025-06-03 15:35:58,028 INFO: Epoch 97, Batch 250, Loss: 0.2875
2025-06-03 15:35:58,764 INFO: Epoch 97, Train Loss: 0.3194
2025-06-03 15:35:58,812 INFO: Epoch 97, Eval Loss: 1.8959
2025-06-03 15:35:58,838 INFO: Epoch 98, Batch 0, Loss: 0.3240
2025-06-03 15:36:00,013 INFO: Epoch 98, Batch 50, Loss: 0.2930
2025-06-03 15:36:01,227 INFO: Epoch 98, Batch 100, Loss: 0.3253
2025-06-03 15:36:02,401 INFO: Epoch 98, Batch 150, Loss: 0.2904
2025-06-03 15:36:03,587 INFO: Epoch 98, Batch 200, Loss: 0.3208
2025-06-03 15:36:04,756 INFO: Epoch 98, Batch 250, Loss: 0.3314
2025-06-03 15:36:05,480 INFO: Epoch 98, Train Loss: 0.3192
2025-06-03 15:36:05,528 INFO: Epoch 98, Eval Loss: 1.8964
2025-06-03 15:36:05,551 INFO: Epoch 99, Batch 0, Loss: 0.3215
2025-06-03 15:36:06,727 INFO: Epoch 99, Batch 50, Loss: 0.3353
2025-06-03 15:36:07,923 INFO: Epoch 99, Batch 100, Loss: 0.3118
2025-06-03 15:36:09,099 INFO: Epoch 99, Batch 150, Loss: 0.3265
2025-06-03 15:36:10,269 INFO: Epoch 99, Batch 200, Loss: 0.3325
2025-06-03 15:36:11,453 INFO: Epoch 99, Batch 250, Loss: 0.3461
2025-06-03 15:36:12,178 INFO: Epoch 99, Train Loss: 0.3209
2025-06-03 15:36:12,227 INFO: Epoch 99, Eval Loss: 1.8961
2025-06-03 15:36:12,249 INFO: Epoch 100, Batch 0, Loss: 0.3427
2025-06-03 15:36:13,426 INFO: Epoch 100, Batch 50, Loss: 0.3062
2025-06-03 15:36:14,605 INFO: Epoch 100, Batch 100, Loss: 0.3233
2025-06-03 15:36:15,782 INFO: Epoch 100, Batch 150, Loss: 0.2708
2025-06-03 15:36:17,007 INFO: Epoch 100, Batch 200, Loss: 0.3328
2025-06-03 15:36:18,183 INFO: Epoch 100, Batch 250, Loss: 0.3471
2025-06-03 15:36:18,890 INFO: Epoch 100, Train Loss: 0.3197
2025-06-03 15:36:18,938 INFO: Epoch 100, Eval Loss: 1.8961