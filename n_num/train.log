2025-06-04 13:26:01,965 INFO: Epoch 0, Batch 0, Loss: 7.4835
2025-06-04 13:26:03,480 INFO: Epoch 0, Batch 50, Loss: 5.0231
2025-06-04 13:26:04,970 INFO: Epoch 0, Batch 100, Loss: 4.9878
2025-06-04 13:26:06,471 INFO: Epoch 0, Batch 150, Loss: 4.7412
2025-06-04 13:26:07,981 INFO: Epoch 0, Batch 200, Loss: 4.7563
2025-06-04 13:26:09,477 INFO: Epoch 0, Batch 250, Loss: 4.3915
2025-06-04 13:26:10,385 INFO: Epoch 0, Train Loss: 4.8283
2025-06-04 13:26:10,450 INFO: Epoch 0, Eval Loss: 4.2624
2025-06-04 13:26:10,582 INFO: New best model saved with loss: 4.2624
2025-06-04 13:26:10,613 INFO: Epoch 1, Batch 0, Loss: 4.4437
2025-06-04 13:26:12,124 INFO: Epoch 1, Batch 50, Loss: 4.2047
2025-06-04 13:26:13,626 INFO: Epoch 1, Batch 100, Loss: 3.9497
2025-06-04 13:26:15,129 INFO: Epoch 1, Batch 150, Loss: 4.0361
2025-06-04 13:26:16,625 INFO: Epoch 1, Batch 200, Loss: 3.9486
2025-06-04 13:26:18,140 INFO: Epoch 1, Batch 250, Loss: 3.9087
2025-06-04 13:26:19,049 INFO: Epoch 1, Train Loss: 4.0963
2025-06-04 13:26:19,111 INFO: Epoch 1, Eval Loss: 3.9605
2025-06-04 13:26:21,422 INFO: New best model saved with loss: 3.9605
2025-06-04 13:26:21,461 INFO: Epoch 2, Batch 0, Loss: 3.9960
2025-06-04 13:26:22,953 INFO: Epoch 2, Batch 50, Loss: 3.8686
2025-06-04 13:26:24,471 INFO: Epoch 2, Batch 100, Loss: 3.8334
2025-06-04 13:26:26,000 INFO: Epoch 2, Batch 150, Loss: 3.7880
2025-06-04 13:26:27,490 INFO: Epoch 2, Batch 200, Loss: 3.7270
2025-06-04 13:26:28,981 INFO: Epoch 2, Batch 250, Loss: 3.5759
2025-06-04 13:26:29,868 INFO: Epoch 2, Train Loss: 3.7840
2025-06-04 13:26:29,929 INFO: Epoch 2, Eval Loss: 3.6623
2025-06-04 13:26:32,263 INFO: New best model saved with loss: 3.6623
2025-06-04 13:26:32,302 INFO: Epoch 3, Batch 0, Loss: 3.6445
2025-06-04 13:26:33,809 INFO: Epoch 3, Batch 50, Loss: 3.5625
2025-06-04 13:26:35,294 INFO: Epoch 3, Batch 100, Loss: 3.5606
2025-06-04 13:26:36,839 INFO: Epoch 3, Batch 150, Loss: 3.3338
2025-06-04 13:26:38,330 INFO: Epoch 3, Batch 200, Loss: 3.4615
2025-06-04 13:26:39,834 INFO: Epoch 3, Batch 250, Loss: 3.3945
2025-06-04 13:26:40,750 INFO: Epoch 3, Train Loss: 3.5372
2025-06-04 13:26:40,812 INFO: Epoch 3, Eval Loss: 3.5065
2025-06-04 13:26:43,122 INFO: New best model saved with loss: 3.5065
2025-06-04 13:26:43,173 INFO: Epoch 4, Batch 0, Loss: 3.4195
2025-06-04 13:26:44,686 INFO: Epoch 4, Batch 50, Loss: 3.3100
2025-06-04 13:26:46,194 INFO: Epoch 4, Batch 100, Loss: 3.3400
2025-06-04 13:26:47,692 INFO: Epoch 4, Batch 150, Loss: 3.3850
2025-06-04 13:26:49,219 INFO: Epoch 4, Batch 200, Loss: 3.2123
2025-06-04 13:26:50,727 INFO: Epoch 4, Batch 250, Loss: 3.2891
2025-06-04 13:26:51,647 INFO: Epoch 4, Train Loss: 3.3274
2025-06-04 13:26:51,708 INFO: Epoch 4, Eval Loss: 3.2831
2025-06-04 13:26:54,012 INFO: New best model saved with loss: 3.2831
2025-06-04 13:26:54,050 INFO: Epoch 5, Batch 0, Loss: 3.2315
2025-06-04 13:26:55,554 INFO: Epoch 5, Batch 50, Loss: 3.0554
2025-06-04 13:26:57,065 INFO: Epoch 5, Batch 100, Loss: 3.0158
2025-06-04 13:26:58,562 INFO: Epoch 5, Batch 150, Loss: 2.9738
2025-06-04 13:27:00,044 INFO: Epoch 5, Batch 200, Loss: 3.0399
2025-06-04 13:27:01,553 INFO: Epoch 5, Batch 250, Loss: 3.1872
2025-06-04 13:27:02,468 INFO: Epoch 5, Train Loss: 3.1333
2025-06-04 13:27:02,529 INFO: Epoch 5, Eval Loss: 3.1223
2025-06-04 13:27:04,796 INFO: New best model saved with loss: 3.1223
2025-06-04 13:27:04,837 INFO: Epoch 6, Batch 0, Loss: 2.9680
2025-06-04 13:27:06,329 INFO: Epoch 6, Batch 50, Loss: 3.0731
2025-06-04 13:27:07,854 INFO: Epoch 6, Batch 100, Loss: 2.9316
2025-06-04 13:27:09,356 INFO: Epoch 6, Batch 150, Loss: 3.0398
2025-06-04 13:27:10,838 INFO: Epoch 6, Batch 200, Loss: 3.0825
2025-06-04 13:27:12,362 INFO: Epoch 6, Batch 250, Loss: 2.7404
2025-06-04 13:27:13,292 INFO: Epoch 6, Train Loss: 2.9567
2025-06-04 13:27:13,353 INFO: Epoch 6, Eval Loss: 3.0254
2025-06-04 13:27:15,554 INFO: New best model saved with loss: 3.0254
2025-06-04 13:27:15,613 INFO: Epoch 7, Batch 0, Loss: 2.6753
2025-06-04 13:27:17,110 INFO: Epoch 7, Batch 50, Loss: 2.5922
2025-06-04 13:27:18,582 INFO: Epoch 7, Batch 100, Loss: 2.6716
2025-06-04 13:27:20,085 INFO: Epoch 7, Batch 150, Loss: 3.0402
2025-06-04 13:27:21,597 INFO: Epoch 7, Batch 200, Loss: 2.9661
2025-06-04 13:27:23,119 INFO: Epoch 7, Batch 250, Loss: 2.8195
2025-06-04 13:27:24,030 INFO: Epoch 7, Train Loss: 2.8053
2025-06-04 13:27:24,090 INFO: Epoch 7, Eval Loss: 2.9505
2025-06-04 13:27:26,062 INFO: New best model saved with loss: 2.9505
2025-06-04 13:27:26,148 INFO: Epoch 8, Batch 0, Loss: 2.7535
2025-06-04 13:27:27,619 INFO: Epoch 8, Batch 50, Loss: 2.6997
2025-06-04 13:27:29,135 INFO: Epoch 8, Batch 100, Loss: 2.5139
2025-06-04 13:27:30,631 INFO: Epoch 8, Batch 150, Loss: 2.4005
2025-06-04 13:27:32,109 INFO: Epoch 8, Batch 200, Loss: 2.5830
2025-06-04 13:27:33,615 INFO: Epoch 8, Batch 250, Loss: 2.6608
2025-06-04 13:27:34,550 INFO: Epoch 8, Train Loss: 2.6719
2025-06-04 13:27:34,611 INFO: Epoch 8, Eval Loss: 2.8095
2025-06-04 13:27:36,401 INFO: New best model saved with loss: 2.8095
2025-06-04 13:27:36,439 INFO: Epoch 9, Batch 0, Loss: 2.5905
2025-06-04 13:27:37,930 INFO: Epoch 9, Batch 50, Loss: 2.4932
2025-06-04 13:27:39,381 INFO: Epoch 9, Batch 100, Loss: 2.5269
2025-06-04 13:27:40,860 INFO: Epoch 9, Batch 150, Loss: 2.5562
2025-06-04 13:27:42,342 INFO: Epoch 9, Batch 200, Loss: 2.4260
2025-06-04 13:27:43,834 INFO: Epoch 9, Batch 250, Loss: 2.4828
2025-06-04 13:27:44,792 INFO: Epoch 9, Train Loss: 2.5494
2025-06-04 13:27:44,853 INFO: Epoch 9, Eval Loss: 2.7528
2025-06-04 13:27:46,364 INFO: New best model saved with loss: 2.7528
2025-06-04 13:27:46,405 INFO: Epoch 10, Batch 0, Loss: 2.4182
2025-06-04 13:27:47,872 INFO: Epoch 10, Batch 50, Loss: 2.4462
2025-06-04 13:27:49,405 INFO: Epoch 10, Batch 100, Loss: 2.5540
2025-06-04 13:27:50,931 INFO: Epoch 10, Batch 150, Loss: 2.3353
2025-06-04 13:27:52,408 INFO: Epoch 10, Batch 200, Loss: 2.3672
2025-06-04 13:27:53,898 INFO: Epoch 10, Batch 250, Loss: 2.5604
2025-06-04 13:27:54,820 INFO: Epoch 10, Train Loss: 2.4399
2025-06-04 13:27:54,881 INFO: Epoch 10, Eval Loss: 2.6405
2025-06-04 13:27:56,445 INFO: New best model saved with loss: 2.6405
2025-06-04 13:27:56,486 INFO: Epoch 11, Batch 0, Loss: 2.3409
2025-06-04 13:27:57,961 INFO: Epoch 11, Batch 50, Loss: 2.3779
2025-06-04 13:27:59,428 INFO: Epoch 11, Batch 100, Loss: 2.2320
2025-06-04 13:28:00,922 INFO: Epoch 11, Batch 150, Loss: 2.3809
2025-06-04 13:28:02,443 INFO: Epoch 11, Batch 200, Loss: 2.5115
2025-06-04 13:28:03,927 INFO: Epoch 11, Batch 250, Loss: 2.4627
2025-06-04 13:28:04,827 INFO: Epoch 11, Train Loss: 2.3380
2025-06-04 13:28:04,888 INFO: Epoch 11, Eval Loss: 2.6071
2025-06-04 13:28:06,769 INFO: New best model saved with loss: 2.6071
2025-06-04 13:28:06,801 INFO: Epoch 12, Batch 0, Loss: 2.3543
2025-06-04 13:28:08,274 INFO: Epoch 12, Batch 50, Loss: 2.1786
2025-06-04 13:28:09,760 INFO: Epoch 12, Batch 100, Loss: 2.2202
2025-06-04 13:28:11,259 INFO: Epoch 12, Batch 150, Loss: 2.0550
2025-06-04 13:28:12,738 INFO: Epoch 12, Batch 200, Loss: 2.1308
2025-06-04 13:28:14,244 INFO: Epoch 12, Batch 250, Loss: 2.2690
2025-06-04 13:28:15,156 INFO: Epoch 12, Train Loss: 2.2447
2025-06-04 13:28:15,216 INFO: Epoch 12, Eval Loss: 2.5807
2025-06-04 13:28:17,621 INFO: New best model saved with loss: 2.5807
2025-06-04 13:28:17,667 INFO: Epoch 13, Batch 0, Loss: 2.3532
2025-06-04 13:28:19,119 INFO: Epoch 13, Batch 50, Loss: 2.1277
2025-06-04 13:28:20,584 INFO: Epoch 13, Batch 100, Loss: 2.0631
2025-06-04 13:28:22,084 INFO: Epoch 13, Batch 150, Loss: 2.1008
2025-06-04 13:28:23,621 INFO: Epoch 13, Batch 200, Loss: 2.2114
2025-06-04 13:28:25,103 INFO: Epoch 13, Batch 250, Loss: 2.1588
2025-06-04 13:28:26,027 INFO: Epoch 13, Train Loss: 2.1555
2025-06-04 13:28:26,088 INFO: Epoch 13, Eval Loss: 2.5178
2025-06-04 13:28:28,772 INFO: New best model saved with loss: 2.5178
2025-06-04 13:28:28,815 INFO: Epoch 14, Batch 0, Loss: 2.0765
2025-06-04 13:28:30,311 INFO: Epoch 14, Batch 50, Loss: 2.0780
2025-06-04 13:28:31,767 INFO: Epoch 14, Batch 100, Loss: 2.0810
2025-06-04 13:28:33,232 INFO: Epoch 14, Batch 150, Loss: 1.9433
2025-06-04 13:28:34,710 INFO: Epoch 14, Batch 200, Loss: 2.2219
2025-06-04 13:28:36,218 INFO: Epoch 14, Batch 250, Loss: 2.3579
2025-06-04 13:28:37,134 INFO: Epoch 14, Train Loss: 2.0761
2025-06-04 13:28:37,195 INFO: Epoch 14, Eval Loss: 2.5065
2025-06-04 13:28:39,677 INFO: New best model saved with loss: 2.5065
2025-06-04 13:28:39,712 INFO: Epoch 15, Batch 0, Loss: 1.9457
2025-06-04 13:28:41,204 INFO: Epoch 15, Batch 50, Loss: 2.1564
2025-06-04 13:28:42,680 INFO: Epoch 15, Batch 100, Loss: 2.0062
2025-06-04 13:28:44,189 INFO: Epoch 15, Batch 150, Loss: 1.9698
2025-06-04 13:28:45,675 INFO: Epoch 15, Batch 200, Loss: 2.1440
2025-06-04 13:28:47,150 INFO: Epoch 15, Batch 250, Loss: 1.9634
2025-06-04 13:28:48,067 INFO: Epoch 15, Train Loss: 1.9920
2025-06-04 13:28:48,128 INFO: Epoch 15, Eval Loss: 2.4578
2025-06-04 13:28:50,415 INFO: New best model saved with loss: 2.4578
2025-06-04 13:28:50,454 INFO: Epoch 16, Batch 0, Loss: 1.8064
2025-06-04 13:28:51,932 INFO: Epoch 16, Batch 50, Loss: 1.9476
2025-06-04 13:28:53,396 INFO: Epoch 16, Batch 100, Loss: 1.9519
2025-06-04 13:28:54,909 INFO: Epoch 16, Batch 150, Loss: 1.8273
2025-06-04 13:28:56,384 INFO: Epoch 16, Batch 200, Loss: 1.9653
2025-06-04 13:28:57,839 INFO: Epoch 16, Batch 250, Loss: 1.7353
2025-06-04 13:28:58,761 INFO: Epoch 16, Train Loss: 1.9188
2025-06-04 13:28:58,820 INFO: Epoch 16, Eval Loss: 2.4525
2025-06-04 13:29:01,093 INFO: New best model saved with loss: 2.4525
2025-06-04 13:29:01,132 INFO: Epoch 17, Batch 0, Loss: 1.9527
2025-06-04 13:29:02,624 INFO: Epoch 17, Batch 50, Loss: 1.8395
2025-06-04 13:29:04,083 INFO: Epoch 17, Batch 100, Loss: 1.8212
2025-06-04 13:29:05,607 INFO: Epoch 17, Batch 150, Loss: 1.9069
2025-06-04 13:29:07,105 INFO: Epoch 17, Batch 200, Loss: 1.7523
2025-06-04 13:29:08,591 INFO: Epoch 17, Batch 250, Loss: 1.8625
2025-06-04 13:29:09,498 INFO: Epoch 17, Train Loss: 1.8468
2025-06-04 13:29:09,559 INFO: Epoch 17, Eval Loss: 2.3919
2025-06-04 13:29:11,648 INFO: New best model saved with loss: 2.3919
2025-06-04 13:29:11,686 INFO: Epoch 18, Batch 0, Loss: 1.8828
2025-06-04 13:29:13,165 INFO: Epoch 18, Batch 50, Loss: 1.7916
2025-06-04 13:29:14,657 INFO: Epoch 18, Batch 100, Loss: 1.5946
2025-06-04 13:29:16,156 INFO: Epoch 18, Batch 150, Loss: 1.7377
2025-06-04 13:29:17,640 INFO: Epoch 18, Batch 200, Loss: 1.9063
2025-06-04 13:29:19,142 INFO: Epoch 18, Batch 250, Loss: 1.7841
2025-06-04 13:29:20,058 INFO: Epoch 18, Train Loss: 1.7790
2025-06-04 13:29:20,119 INFO: Epoch 18, Eval Loss: 2.3704
2025-06-04 13:29:22,251 INFO: New best model saved with loss: 2.3704
2025-06-04 13:29:22,285 INFO: Epoch 19, Batch 0, Loss: 1.9681
2025-06-04 13:29:23,786 INFO: Epoch 19, Batch 50, Loss: 1.7134
2025-06-04 13:29:25,285 INFO: Epoch 19, Batch 100, Loss: 1.5920
2025-06-04 13:29:26,748 INFO: Epoch 19, Batch 150, Loss: 1.7228
2025-06-04 13:29:28,221 INFO: Epoch 19, Batch 200, Loss: 1.6142
2025-06-04 13:29:29,703 INFO: Epoch 19, Batch 250, Loss: 1.7097
2025-06-04 13:29:30,646 INFO: Epoch 19, Train Loss: 1.7131
2025-06-04 13:29:30,706 INFO: Epoch 19, Eval Loss: 2.3304
2025-06-04 13:29:32,745 INFO: New best model saved with loss: 2.3304
2025-06-04 13:29:32,782 INFO: Epoch 20, Batch 0, Loss: 1.6571
2025-06-04 13:29:34,253 INFO: Epoch 20, Batch 50, Loss: 1.6308
2025-06-04 13:29:35,723 INFO: Epoch 20, Batch 100, Loss: 1.8183
2025-06-04 13:29:37,220 INFO: Epoch 20, Batch 150, Loss: 1.5107
2025-06-04 13:29:38,732 INFO: Epoch 20, Batch 200, Loss: 1.5923
2025-06-04 13:29:40,213 INFO: Epoch 20, Batch 250, Loss: 1.6013
2025-06-04 13:29:41,134 INFO: Epoch 20, Train Loss: 1.6519
2025-06-04 13:29:41,195 INFO: Epoch 20, Eval Loss: 2.2519
2025-06-04 13:29:42,632 INFO: New best model saved with loss: 2.2519
2025-06-04 13:29:42,676 INFO: Epoch 21, Batch 0, Loss: 1.5157
2025-06-04 13:29:44,150 INFO: Epoch 21, Batch 50, Loss: 1.4688
2025-06-04 13:29:45,657 INFO: Epoch 21, Batch 100, Loss: 1.4299
2025-06-04 13:29:47,149 INFO: Epoch 21, Batch 150, Loss: 1.4962
2025-06-04 13:29:48,620 INFO: Epoch 21, Batch 200, Loss: 1.6675
2025-06-04 13:29:50,129 INFO: Epoch 21, Batch 250, Loss: 1.6779
2025-06-04 13:29:51,049 INFO: Epoch 21, Train Loss: 1.5914
2025-06-04 13:29:51,109 INFO: Epoch 21, Eval Loss: 2.2089
2025-06-04 13:29:52,540 INFO: New best model saved with loss: 2.2089
2025-06-04 13:29:52,579 INFO: Epoch 22, Batch 0, Loss: 1.4118
2025-06-04 13:29:54,079 INFO: Epoch 22, Batch 50, Loss: 1.5209
2025-06-04 13:29:55,540 INFO: Epoch 22, Batch 100, Loss: 1.4621
2025-06-04 13:29:57,039 INFO: Epoch 22, Batch 150, Loss: 1.5063
2025-06-04 13:29:58,537 INFO: Epoch 22, Batch 200, Loss: 1.5784
2025-06-04 13:30:00,021 INFO: Epoch 22, Batch 250, Loss: 1.6641
2025-06-04 13:30:00,934 INFO: Epoch 22, Train Loss: 1.5339
2025-06-04 13:30:00,995 INFO: Epoch 22, Eval Loss: 2.2138
2025-06-04 13:30:01,026 INFO: Epoch 23, Batch 0, Loss: 1.4714
2025-06-04 13:30:02,523 INFO: Epoch 23, Batch 50, Loss: 1.4023
2025-06-04 13:30:04,025 INFO: Epoch 23, Batch 100, Loss: 1.5175
2025-06-04 13:30:05,532 INFO: Epoch 23, Batch 150, Loss: 1.5736
2025-06-04 13:30:07,027 INFO: Epoch 23, Batch 200, Loss: 1.4284
2025-06-04 13:30:08,544 INFO: Epoch 23, Batch 250, Loss: 1.4029
2025-06-04 13:30:09,474 INFO: Epoch 23, Train Loss: 1.4790
2025-06-04 13:30:09,535 INFO: Epoch 23, Eval Loss: 2.1696
2025-06-04 13:30:10,970 INFO: New best model saved with loss: 2.1696
2025-06-04 13:30:11,010 INFO: Epoch 24, Batch 0, Loss: 1.3900
2025-06-04 13:30:12,534 INFO: Epoch 24, Batch 50, Loss: 1.3711
2025-06-04 13:30:14,039 INFO: Epoch 24, Batch 100, Loss: 1.6197
2025-06-04 13:30:15,496 INFO: Epoch 24, Batch 150, Loss: 1.3004
2025-06-04 13:30:17,010 INFO: Epoch 24, Batch 200, Loss: 1.4782
2025-06-04 13:30:18,497 INFO: Epoch 24, Batch 250, Loss: 1.4822
2025-06-04 13:30:19,382 INFO: Epoch 24, Train Loss: 1.4264
2025-06-04 13:30:19,443 INFO: Epoch 24, Eval Loss: 2.1393
2025-06-04 13:30:20,796 INFO: New best model saved with loss: 2.1393
2025-06-04 13:30:20,832 INFO: Epoch 25, Batch 0, Loss: 1.4473
2025-06-04 13:30:22,314 INFO: Epoch 25, Batch 50, Loss: 1.2775
2025-06-04 13:30:23,783 INFO: Epoch 25, Batch 100, Loss: 1.3331
2025-06-04 13:30:25,294 INFO: Epoch 25, Batch 150, Loss: 1.2928
2025-06-04 13:30:26,788 INFO: Epoch 25, Batch 200, Loss: 1.3337
2025-06-04 13:30:28,261 INFO: Epoch 25, Batch 250, Loss: 1.4489
2025-06-04 13:30:29,201 INFO: Epoch 25, Train Loss: 1.3752
2025-06-04 13:30:29,262 INFO: Epoch 25, Eval Loss: 2.1740
2025-06-04 13:30:29,290 INFO: Epoch 26, Batch 0, Loss: 1.2525
2025-06-04 13:30:30,807 INFO: Epoch 26, Batch 50, Loss: 1.4060
2025-06-04 13:30:32,293 INFO: Epoch 26, Batch 100, Loss: 1.2584
2025-06-04 13:30:33,779 INFO: Epoch 26, Batch 150, Loss: 1.4953
2025-06-04 13:30:35,295 INFO: Epoch 26, Batch 200, Loss: 1.4427
2025-06-04 13:30:36,798 INFO: Epoch 26, Batch 250, Loss: 1.3839
2025-06-04 13:30:37,708 INFO: Epoch 26, Train Loss: 1.3257
2025-06-04 13:30:37,769 INFO: Epoch 26, Eval Loss: 2.1007
2025-06-04 13:30:39,491 INFO: New best model saved with loss: 2.1007
2025-06-04 13:30:39,544 INFO: Epoch 27, Batch 0, Loss: 1.2755
2025-06-04 13:30:41,033 INFO: Epoch 27, Batch 50, Loss: 1.2060
2025-06-04 13:30:42,543 INFO: Epoch 27, Batch 100, Loss: 1.2994
2025-06-04 13:30:44,021 INFO: Epoch 27, Batch 150, Loss: 1.3471
2025-06-04 13:30:45,523 INFO: Epoch 27, Batch 200, Loss: 1.3511
2025-06-04 13:30:47,030 INFO: Epoch 27, Batch 250, Loss: 1.2306
2025-06-04 13:30:47,945 INFO: Epoch 27, Train Loss: 1.2767
2025-06-04 13:30:48,006 INFO: Epoch 27, Eval Loss: 2.1491
2025-06-04 13:30:48,038 INFO: Epoch 28, Batch 0, Loss: 1.2832
2025-06-04 13:30:49,539 INFO: Epoch 28, Batch 50, Loss: 1.0937
2025-06-04 13:30:51,027 INFO: Epoch 28, Batch 100, Loss: 1.1585
2025-06-04 13:30:52,510 INFO: Epoch 28, Batch 150, Loss: 1.2425
2025-06-04 13:30:54,012 INFO: Epoch 28, Batch 200, Loss: 1.2026
2025-06-04 13:30:55,512 INFO: Epoch 28, Batch 250, Loss: 1.2984
2025-06-04 13:30:56,408 INFO: Epoch 28, Train Loss: 1.2322
2025-06-04 13:30:56,468 INFO: Epoch 28, Eval Loss: 2.1412
2025-06-04 13:30:56,499 INFO: Epoch 29, Batch 0, Loss: 1.1910
2025-06-04 13:30:57,964 INFO: Epoch 29, Batch 50, Loss: 1.1693
2025-06-04 13:30:59,476 INFO: Epoch 29, Batch 100, Loss: 1.2839
2025-06-04 13:31:00,963 INFO: Epoch 29, Batch 150, Loss: 1.1830
2025-06-04 13:31:02,435 INFO: Epoch 29, Batch 200, Loss: 1.0184
2025-06-04 13:31:03,933 INFO: Epoch 29, Batch 250, Loss: 1.1783
2025-06-04 13:31:04,847 INFO: Epoch 29, Train Loss: 1.1835
2025-06-04 13:31:04,908 INFO: Epoch 29, Eval Loss: 2.1735
2025-06-04 13:31:04,941 INFO: Epoch 30, Batch 0, Loss: 1.1717
2025-06-04 13:31:06,453 INFO: Epoch 30, Batch 50, Loss: 1.0901
2025-06-04 13:31:07,936 INFO: Epoch 30, Batch 100, Loss: 1.1909
2025-06-04 13:31:09,402 INFO: Epoch 30, Batch 150, Loss: 1.1798
2025-06-04 13:31:10,891 INFO: Epoch 30, Batch 200, Loss: 1.1116
2025-06-04 13:31:12,416 INFO: Epoch 30, Batch 250, Loss: 1.1549
2025-06-04 13:31:13,323 INFO: Epoch 30, Train Loss: 1.1416
2025-06-04 13:31:13,385 INFO: Epoch 30, Eval Loss: 2.1341
2025-06-04 13:31:13,413 INFO: Epoch 31, Batch 0, Loss: 1.0339
2025-06-04 13:31:14,880 INFO: Epoch 31, Batch 50, Loss: 0.9279
2025-06-04 13:31:16,387 INFO: Epoch 31, Batch 100, Loss: 1.0013
2025-06-04 13:31:17,893 INFO: Epoch 31, Batch 150, Loss: 1.0579
2025-06-04 13:31:19,386 INFO: Epoch 31, Batch 200, Loss: 1.1156
2025-06-04 13:31:20,887 INFO: Epoch 31, Batch 250, Loss: 1.0682
2025-06-04 13:31:21,803 INFO: Epoch 31, Train Loss: 1.0254
2025-06-04 13:31:21,864 INFO: Epoch 31, Eval Loss: 2.0764
2025-06-04 13:31:24,544 INFO: New best model saved with loss: 2.0764
2025-06-04 13:31:24,584 INFO: Epoch 32, Batch 0, Loss: 0.9752
2025-06-04 13:31:26,051 INFO: Epoch 32, Batch 50, Loss: 0.9309
2025-06-04 13:31:27,537 INFO: Epoch 32, Batch 100, Loss: 1.0176
2025-06-04 13:31:29,054 INFO: Epoch 32, Batch 150, Loss: 1.0546
2025-06-04 13:31:30,537 INFO: Epoch 32, Batch 200, Loss: 1.0775
2025-06-04 13:31:32,002 INFO: Epoch 32, Batch 250, Loss: 0.9408
2025-06-04 13:31:32,915 INFO: Epoch 32, Train Loss: 0.9806
2025-06-04 13:31:32,975 INFO: Epoch 32, Eval Loss: 2.0425
2025-06-04 13:31:35,890 INFO: New best model saved with loss: 2.0425
2025-06-04 13:31:35,934 INFO: Epoch 33, Batch 0, Loss: 0.8949
2025-06-04 13:31:37,407 INFO: Epoch 33, Batch 50, Loss: 0.9727
2025-06-04 13:31:38,903 INFO: Epoch 33, Batch 100, Loss: 0.9185
2025-06-04 13:31:40,415 INFO: Epoch 33, Batch 150, Loss: 0.9345
2025-06-04 13:31:41,929 INFO: Epoch 33, Batch 200, Loss: 1.0378
2025-06-04 13:31:43,430 INFO: Epoch 33, Batch 250, Loss: 0.9985
2025-06-04 13:31:44,338 INFO: Epoch 33, Train Loss: 0.9502
2025-06-04 13:31:44,400 INFO: Epoch 33, Eval Loss: 2.0613
2025-06-04 13:31:44,432 INFO: Epoch 34, Batch 0, Loss: 0.9490
2025-06-04 13:31:45,988 INFO: Epoch 34, Batch 50, Loss: 0.8960
2025-06-04 13:31:47,497 INFO: Epoch 34, Batch 100, Loss: 0.8021
2025-06-04 13:31:49,005 INFO: Epoch 34, Batch 150, Loss: 0.8447
2025-06-04 13:31:50,499 INFO: Epoch 34, Batch 200, Loss: 0.8127
2025-06-04 13:31:51,984 INFO: Epoch 34, Batch 250, Loss: 0.9478
2025-06-04 13:31:52,893 INFO: Epoch 34, Train Loss: 0.9229
2025-06-04 13:31:52,955 INFO: Epoch 34, Eval Loss: 2.0577
2025-06-04 13:31:52,987 INFO: Epoch 35, Batch 0, Loss: 0.8783
2025-06-04 13:31:54,500 INFO: Epoch 35, Batch 50, Loss: 0.8465
2025-06-04 13:31:56,024 INFO: Epoch 35, Batch 100, Loss: 0.9839
2025-06-04 13:31:57,510 INFO: Epoch 35, Batch 150, Loss: 0.9286
2025-06-04 13:31:59,013 INFO: Epoch 35, Batch 200, Loss: 0.8896
2025-06-04 13:32:00,533 INFO: Epoch 35, Batch 250, Loss: 0.9774
2025-06-04 13:32:01,446 INFO: Epoch 35, Train Loss: 0.8999
2025-06-04 13:32:01,506 INFO: Epoch 35, Eval Loss: 2.0666
2025-06-04 13:32:01,535 INFO: Epoch 36, Batch 0, Loss: 0.7451
2025-06-04 13:32:03,040 INFO: Epoch 36, Batch 50, Loss: 0.9015
2025-06-04 13:32:04,550 INFO: Epoch 36, Batch 100, Loss: 0.8546
2025-06-04 13:32:06,081 INFO: Epoch 36, Batch 150, Loss: 0.9347
2025-06-04 13:32:07,579 INFO: Epoch 36, Batch 200, Loss: 0.8465
2025-06-04 13:32:09,076 INFO: Epoch 36, Batch 250, Loss: 0.8752
2025-06-04 13:32:09,989 INFO: Epoch 36, Train Loss: 0.8756
2025-06-04 13:32:10,051 INFO: Epoch 36, Eval Loss: 2.0813
2025-06-04 13:32:10,081 INFO: Epoch 37, Batch 0, Loss: 0.9492
2025-06-04 13:32:11,611 INFO: Epoch 37, Batch 50, Loss: 0.7384
2025-06-04 13:32:13,112 INFO: Epoch 37, Batch 100, Loss: 0.8030
2025-06-04 13:32:14,657 INFO: Epoch 37, Batch 150, Loss: 0.7492
2025-06-04 13:32:16,179 INFO: Epoch 37, Batch 200, Loss: 0.7821
2025-06-04 13:32:17,663 INFO: Epoch 37, Batch 250, Loss: 0.8114
2025-06-04 13:32:18,609 INFO: Epoch 37, Train Loss: 0.8193
2025-06-04 13:32:18,671 INFO: Epoch 37, Eval Loss: 2.0518
2025-06-04 13:32:18,702 INFO: Epoch 38, Batch 0, Loss: 0.7281
2025-06-04 13:32:20,204 INFO: Epoch 38, Batch 50, Loss: 0.8631
2025-06-04 13:32:21,710 INFO: Epoch 38, Batch 100, Loss: 0.7864
2025-06-04 13:32:23,202 INFO: Epoch 38, Batch 150, Loss: 0.8048
2025-06-04 13:32:24,681 INFO: Epoch 38, Batch 200, Loss: 0.8480
2025-06-04 13:32:26,189 INFO: Epoch 38, Batch 250, Loss: 0.7879
2025-06-04 13:32:27,112 INFO: Epoch 38, Train Loss: 0.7957
2025-06-04 13:32:27,174 INFO: Epoch 38, Eval Loss: 2.0593
2025-06-04 13:32:27,205 INFO: Epoch 39, Batch 0, Loss: 0.7242
2025-06-04 13:32:28,733 INFO: Epoch 39, Batch 50, Loss: 0.6135
2025-06-04 13:32:30,245 INFO: Epoch 39, Batch 100, Loss: 0.6922
2025-06-04 13:32:31,724 INFO: Epoch 39, Batch 150, Loss: 0.6700
2025-06-04 13:32:33,216 INFO: Epoch 39, Batch 200, Loss: 0.8265
2025-06-04 13:32:34,685 INFO: Epoch 39, Batch 250, Loss: 0.6876
2025-06-04 13:32:35,609 INFO: Epoch 39, Train Loss: 0.7825
2025-06-04 13:32:35,669 INFO: Epoch 39, Eval Loss: 2.0713
2025-06-04 13:32:35,699 INFO: Epoch 40, Batch 0, Loss: 0.7078
2025-06-04 13:32:37,196 INFO: Epoch 40, Batch 50, Loss: 0.8194
2025-06-04 13:32:38,712 INFO: Epoch 40, Batch 100, Loss: 0.7365
2025-06-04 13:32:40,192 INFO: Epoch 40, Batch 150, Loss: 0.7456
2025-06-04 13:32:41,681 INFO: Epoch 40, Batch 200, Loss: 0.8046
2025-06-04 13:32:43,183 INFO: Epoch 40, Batch 250, Loss: 0.8913
2025-06-04 13:32:44,156 INFO: Epoch 40, Train Loss: 0.7701
2025-06-04 13:32:44,217 INFO: Epoch 40, Eval Loss: 2.0503
2025-06-04 13:32:44,248 INFO: Epoch 41, Batch 0, Loss: 0.8310
2025-06-04 13:32:45,740 INFO: Epoch 41, Batch 50, Loss: 0.7718
2025-06-04 13:32:47,252 INFO: Epoch 41, Batch 100, Loss: 0.8170
2025-06-04 13:32:48,767 INFO: Epoch 41, Batch 150, Loss: 0.8598
2025-06-04 13:32:50,275 INFO: Epoch 41, Batch 200, Loss: 0.6877
2025-06-04 13:32:51,768 INFO: Epoch 41, Batch 250, Loss: 0.7278
2025-06-04 13:32:52,668 INFO: Epoch 41, Train Loss: 0.7397
2025-06-04 13:32:52,729 INFO: Epoch 41, Eval Loss: 2.0579
2025-06-04 13:32:52,760 INFO: Epoch 42, Batch 0, Loss: 0.6900
2025-06-04 13:32:54,249 INFO: Epoch 42, Batch 50, Loss: 0.6874
2025-06-04 13:32:55,741 INFO: Epoch 42, Batch 100, Loss: 0.7582
2025-06-04 13:32:57,251 INFO: Epoch 42, Batch 150, Loss: 0.8077
2025-06-04 13:32:58,754 INFO: Epoch 42, Batch 200, Loss: 0.7684
2025-06-04 13:33:00,251 INFO: Epoch 42, Batch 250, Loss: 0.7952
2025-06-04 13:33:01,172 INFO: Epoch 42, Train Loss: 0.7306
2025-06-04 13:33:01,232 INFO: Epoch 42, Eval Loss: 2.0370
2025-06-04 13:33:04,110 INFO: New best model saved with loss: 2.0370
2025-06-04 13:33:04,152 INFO: Epoch 43, Batch 0, Loss: 0.6986
2025-06-04 13:33:05,655 INFO: Epoch 43, Batch 50, Loss: 0.7136
2025-06-04 13:33:07,130 INFO: Epoch 43, Batch 100, Loss: 0.6852
2025-06-04 13:33:08,607 INFO: Epoch 43, Batch 150, Loss: 0.7821
2025-06-04 13:33:10,078 INFO: Epoch 43, Batch 200, Loss: 0.7249
2025-06-04 13:33:11,581 INFO: Epoch 43, Batch 250, Loss: 0.8149
2025-06-04 13:33:12,524 INFO: Epoch 43, Train Loss: 0.7217
2025-06-04 13:33:12,584 INFO: Epoch 43, Eval Loss: 2.0466
2025-06-04 13:33:12,619 INFO: Epoch 44, Batch 0, Loss: 0.6879
2025-06-04 13:33:14,105 INFO: Epoch 44, Batch 50, Loss: 0.6386
2025-06-04 13:33:15,611 INFO: Epoch 44, Batch 100, Loss: 0.7706
2025-06-04 13:33:17,129 INFO: Epoch 44, Batch 150, Loss: 0.7270
2025-06-04 13:33:18,619 INFO: Epoch 44, Batch 200, Loss: 0.7650
2025-06-04 13:33:20,106 INFO: Epoch 44, Batch 250, Loss: 0.7202
2025-06-04 13:33:21,003 INFO: Epoch 44, Train Loss: 0.7130
2025-06-04 13:33:21,064 INFO: Epoch 44, Eval Loss: 2.0347
2025-06-04 13:33:23,775 INFO: New best model saved with loss: 2.0347
2025-06-04 13:33:23,819 INFO: Epoch 45, Batch 0, Loss: 0.6664
2025-06-04 13:33:25,304 INFO: Epoch 45, Batch 50, Loss: 0.8201
2025-06-04 13:33:26,790 INFO: Epoch 45, Batch 100, Loss: 0.7215
2025-06-04 13:33:28,291 INFO: Epoch 45, Batch 150, Loss: 0.7075
2025-06-04 13:33:29,789 INFO: Epoch 45, Batch 200, Loss: 0.7999
2025-06-04 13:33:31,298 INFO: Epoch 45, Batch 250, Loss: 0.6554
2025-06-04 13:33:32,193 INFO: Epoch 45, Train Loss: 0.7063
2025-06-04 13:33:32,254 INFO: Epoch 45, Eval Loss: 2.0386
2025-06-04 13:33:32,291 INFO: Epoch 46, Batch 0, Loss: 0.7295
2025-06-04 13:33:33,768 INFO: Epoch 46, Batch 50, Loss: 0.6682
2025-06-04 13:33:35,268 INFO: Epoch 46, Batch 100, Loss: 0.6747
2025-06-04 13:33:36,746 INFO: Epoch 46, Batch 150, Loss: 0.6270
2025-06-04 13:33:38,226 INFO: Epoch 46, Batch 200, Loss: 0.7052
2025-06-04 13:33:39,749 INFO: Epoch 46, Batch 250, Loss: 0.6825
2025-06-04 13:33:40,675 INFO: Epoch 46, Train Loss: 0.7018
2025-06-04 13:33:40,735 INFO: Epoch 46, Eval Loss: 2.0295
2025-06-04 13:33:43,447 INFO: New best model saved with loss: 2.0295
2025-06-04 13:33:43,486 INFO: Epoch 47, Batch 0, Loss: 0.6691
2025-06-04 13:33:44,983 INFO: Epoch 47, Batch 50, Loss: 0.6391
2025-06-04 13:33:46,484 INFO: Epoch 47, Batch 100, Loss: 0.6783
2025-06-04 13:33:47,989 INFO: Epoch 47, Batch 150, Loss: 0.6449
2025-06-04 13:33:49,478 INFO: Epoch 47, Batch 200, Loss: 0.7482
2025-06-04 13:33:50,971 INFO: Epoch 47, Batch 250, Loss: 0.7188
2025-06-04 13:33:51,894 INFO: Epoch 47, Train Loss: 0.6913
2025-06-04 13:33:51,955 INFO: Epoch 47, Eval Loss: 2.0249
2025-06-04 13:33:54,881 INFO: New best model saved with loss: 2.0249
2025-06-04 13:33:54,924 INFO: Epoch 48, Batch 0, Loss: 0.7633
2025-06-04 13:33:56,420 INFO: Epoch 48, Batch 50, Loss: 0.7057
2025-06-04 13:33:57,926 INFO: Epoch 48, Batch 100, Loss: 0.6813
2025-06-04 13:33:59,420 INFO: Epoch 48, Batch 150, Loss: 0.6230
2025-06-04 13:34:00,902 INFO: Epoch 48, Batch 200, Loss: 0.5922
2025-06-04 13:34:02,404 INFO: Epoch 48, Batch 250, Loss: 0.6753
2025-06-04 13:34:03,305 INFO: Epoch 48, Train Loss: 0.6869
2025-06-04 13:34:03,365 INFO: Epoch 48, Eval Loss: 2.0356
2025-06-04 13:34:03,393 INFO: Epoch 49, Batch 0, Loss: 0.6859
2025-06-04 13:34:04,868 INFO: Epoch 49, Batch 50, Loss: 0.7207
2025-06-04 13:34:06,348 INFO: Epoch 49, Batch 100, Loss: 0.6954
2025-06-04 13:34:07,890 INFO: Epoch 49, Batch 150, Loss: 0.6370
2025-06-04 13:34:09,374 INFO: Epoch 49, Batch 200, Loss: 0.6237
2025-06-04 13:34:10,853 INFO: Epoch 49, Batch 250, Loss: 0.6858
2025-06-04 13:34:11,761 INFO: Epoch 49, Train Loss: 0.6809
2025-06-04 13:34:11,821 INFO: Epoch 49, Eval Loss: 2.0376
2025-06-04 13:34:11,852 INFO: Epoch 50, Batch 0, Loss: 0.7413
2025-06-04 13:34:13,339 INFO: Epoch 50, Batch 50, Loss: 0.6448
2025-06-04 13:34:14,822 INFO: Epoch 50, Batch 100, Loss: 0.7155
2025-06-04 13:34:16,294 INFO: Epoch 50, Batch 150, Loss: 0.6634
2025-06-04 13:34:17,790 INFO: Epoch 50, Batch 200, Loss: 0.7076
2025-06-04 13:34:19,296 INFO: Epoch 50, Batch 250, Loss: 0.7403
2025-06-04 13:34:20,211 INFO: Epoch 50, Train Loss: 0.6739
2025-06-04 13:34:20,271 INFO: Epoch 50, Eval Loss: 2.0400
2025-06-04 13:34:20,302 INFO: Epoch 51, Batch 0, Loss: 0.5867
2025-06-04 13:34:21,798 INFO: Epoch 51, Batch 50, Loss: 0.7075
2025-06-04 13:34:23,307 INFO: Epoch 51, Batch 100, Loss: 0.6835
2025-06-04 13:34:24,794 INFO: Epoch 51, Batch 150, Loss: 0.7719
2025-06-04 13:34:26,325 INFO: Epoch 51, Batch 200, Loss: 0.7042
2025-06-04 13:34:27,834 INFO: Epoch 51, Batch 250, Loss: 0.7622
2025-06-04 13:34:28,745 INFO: Epoch 51, Train Loss: 0.6686
2025-06-04 13:34:28,805 INFO: Epoch 51, Eval Loss: 2.0424
2025-06-04 13:34:28,835 INFO: Epoch 52, Batch 0, Loss: 0.6513
2025-06-04 13:34:30,343 INFO: Epoch 52, Batch 50, Loss: 0.6495
2025-06-04 13:34:31,815 INFO: Epoch 52, Batch 100, Loss: 0.6908
2025-06-04 13:34:33,325 INFO: Epoch 52, Batch 150, Loss: 0.6000
2025-06-04 13:34:34,835 INFO: Epoch 52, Batch 200, Loss: 0.5277
2025-06-04 13:34:36,313 INFO: Epoch 52, Batch 250, Loss: 0.6419
2025-06-04 13:34:37,233 INFO: Epoch 52, Train Loss: 0.6544
2025-06-04 13:34:37,295 INFO: Epoch 52, Eval Loss: 2.0337
2025-06-04 13:34:37,328 INFO: Epoch 53, Batch 0, Loss: 0.7174
2025-06-04 13:34:38,801 INFO: Epoch 53, Batch 50, Loss: 0.6662
2025-06-04 13:34:40,291 INFO: Epoch 53, Batch 100, Loss: 0.6520
2025-06-04 13:34:41,779 INFO: Epoch 53, Batch 150, Loss: 0.6578
2025-06-04 13:34:43,281 INFO: Epoch 53, Batch 200, Loss: 0.6572
2025-06-04 13:34:44,789 INFO: Epoch 53, Batch 250, Loss: 0.6450
2025-06-04 13:34:45,711 INFO: Epoch 53, Train Loss: 0.6507
2025-06-04 13:34:45,772 INFO: Epoch 53, Eval Loss: 2.0316
2025-06-04 13:34:45,802 INFO: Epoch 54, Batch 0, Loss: 0.6212
2025-06-04 13:34:47,294 INFO: Epoch 54, Batch 50, Loss: 0.7015
2025-06-04 13:34:48,775 INFO: Epoch 54, Batch 100, Loss: 0.6368
2025-06-04 13:34:50,264 INFO: Epoch 54, Batch 150, Loss: 0.6375
2025-06-04 13:34:51,787 INFO: Epoch 54, Batch 200, Loss: 0.6407
2025-06-04 13:34:53,272 INFO: Epoch 54, Batch 250, Loss: 0.5323
2025-06-04 13:34:54,200 INFO: Epoch 54, Train Loss: 0.6477
2025-06-04 13:34:54,261 INFO: Epoch 54, Eval Loss: 2.0448
2025-06-04 13:34:54,294 INFO: Epoch 55, Batch 0, Loss: 0.5982
2025-06-04 13:34:55,785 INFO: Epoch 55, Batch 50, Loss: 0.6527
2025-06-04 13:34:57,275 INFO: Epoch 55, Batch 100, Loss: 0.6448
2025-06-04 13:34:58,768 INFO: Epoch 55, Batch 150, Loss: 0.7187
2025-06-04 13:35:00,247 INFO: Epoch 55, Batch 200, Loss: 0.7020
2025-06-04 13:35:01,765 INFO: Epoch 55, Batch 250, Loss: 0.6882
2025-06-04 13:35:02,694 INFO: Epoch 55, Train Loss: 0.6444
2025-06-04 13:35:02,755 INFO: Epoch 55, Eval Loss: 2.0279
2025-06-04 13:35:02,783 INFO: Epoch 56, Batch 0, Loss: 0.5788
2025-06-04 13:35:04,276 INFO: Epoch 56, Batch 50, Loss: 0.5948
2025-06-04 13:35:05,780 INFO: Epoch 56, Batch 100, Loss: 0.5799
2025-06-04 13:35:07,249 INFO: Epoch 56, Batch 150, Loss: 0.6788
2025-06-04 13:35:08,754 INFO: Epoch 56, Batch 200, Loss: 0.5373
2025-06-04 13:35:10,226 INFO: Epoch 56, Batch 250, Loss: 0.6168
2025-06-04 13:35:11,141 INFO: Epoch 56, Train Loss: 0.6377
2025-06-04 13:35:11,202 INFO: Epoch 56, Eval Loss: 2.0298
2025-06-04 13:35:11,237 INFO: Epoch 57, Batch 0, Loss: 0.7265
2025-06-04 13:35:12,712 INFO: Epoch 57, Batch 50, Loss: 0.5505
2025-06-04 13:35:14,197 INFO: Epoch 57, Batch 100, Loss: 0.5925
2025-06-04 13:35:15,688 INFO: Epoch 57, Batch 150, Loss: 0.6808
2025-06-04 13:35:17,192 INFO: Epoch 57, Batch 200, Loss: 0.6958
2025-06-04 13:35:18,699 INFO: Epoch 57, Batch 250, Loss: 0.6758
2025-06-04 13:35:19,612 INFO: Epoch 57, Train Loss: 0.6376
2025-06-04 13:35:19,673 INFO: Epoch 57, Eval Loss: 2.0346
2025-06-04 13:35:19,705 INFO: Epoch 58, Batch 0, Loss: 0.5965
2025-06-04 13:35:21,198 INFO: Epoch 58, Batch 50, Loss: 0.5874
2025-06-04 13:35:22,699 INFO: Epoch 58, Batch 100, Loss: 0.6614
2025-06-04 13:35:24,186 INFO: Epoch 58, Batch 150, Loss: 0.6340
2025-06-04 13:35:25,678 INFO: Epoch 58, Batch 200, Loss: 0.5888
2025-06-04 13:35:27,170 INFO: Epoch 58, Batch 250, Loss: 0.6054
2025-06-04 13:35:28,094 INFO: Epoch 58, Train Loss: 0.6341
2025-06-04 13:35:28,154 INFO: Epoch 58, Eval Loss: 2.0355
2025-06-04 13:35:28,185 INFO: Epoch 59, Batch 0, Loss: 0.5582
2025-06-04 13:35:29,669 INFO: Epoch 59, Batch 50, Loss: 0.6732
2025-06-04 13:35:31,171 INFO: Epoch 59, Batch 100, Loss: 0.5743
2025-06-04 13:35:32,661 INFO: Epoch 59, Batch 150, Loss: 0.5926
2025-06-04 13:35:34,158 INFO: Epoch 59, Batch 200, Loss: 0.6985
2025-06-04 13:35:35,648 INFO: Epoch 59, Batch 250, Loss: 0.7671
2025-06-04 13:35:36,589 INFO: Epoch 59, Train Loss: 0.6305
2025-06-04 13:35:36,650 INFO: Epoch 59, Eval Loss: 2.0319
2025-06-04 13:35:36,681 INFO: Epoch 60, Batch 0, Loss: 0.5915
2025-06-04 13:35:38,162 INFO: Epoch 60, Batch 50, Loss: 0.6219
2025-06-04 13:35:39,663 INFO: Epoch 60, Batch 100, Loss: 0.6049
2025-06-04 13:35:41,176 INFO: Epoch 60, Batch 150, Loss: 0.6743
2025-06-04 13:35:42,667 INFO: Epoch 60, Batch 200, Loss: 0.5758
2025-06-04 13:35:44,151 INFO: Epoch 60, Batch 250, Loss: 0.6332
2025-06-04 13:35:45,057 INFO: Epoch 60, Train Loss: 0.6291
2025-06-04 13:35:45,118 INFO: Epoch 60, Eval Loss: 2.0341
2025-06-04 13:35:45,150 INFO: Epoch 61, Batch 0, Loss: 0.6827
2025-06-04 13:35:46,639 INFO: Epoch 61, Batch 50, Loss: 0.6746
2025-06-04 13:35:48,110 INFO: Epoch 61, Batch 100, Loss: 0.6061
2025-06-04 13:35:49,598 INFO: Epoch 61, Batch 150, Loss: 0.5812
2025-06-04 13:35:51,131 INFO: Epoch 61, Batch 200, Loss: 0.5915
2025-06-04 13:35:52,636 INFO: Epoch 61, Batch 250, Loss: 0.6485
2025-06-04 13:35:53,568 INFO: Epoch 61, Train Loss: 0.6257
2025-06-04 13:35:53,629 INFO: Epoch 61, Eval Loss: 2.0319
2025-06-04 13:35:53,660 INFO: Epoch 62, Batch 0, Loss: 0.5996
2025-06-04 13:35:55,156 INFO: Epoch 62, Batch 50, Loss: 0.6098
2025-06-04 13:35:56,667 INFO: Epoch 62, Batch 100, Loss: 0.7199
2025-06-04 13:35:58,130 INFO: Epoch 62, Batch 150, Loss: 0.5347
2025-06-04 13:35:59,633 INFO: Epoch 62, Batch 200, Loss: 0.6018
2025-06-04 13:36:01,129 INFO: Epoch 62, Batch 250, Loss: 0.6815
2025-06-04 13:36:02,037 INFO: Epoch 62, Train Loss: 0.6250
2025-06-04 13:36:02,098 INFO: Epoch 62, Eval Loss: 2.0389
2025-06-04 13:36:02,130 INFO: Epoch 63, Batch 0, Loss: 0.6396
2025-06-04 13:36:03,626 INFO: Epoch 63, Batch 50, Loss: 0.7302
2025-06-04 13:36:05,125 INFO: Epoch 63, Batch 100, Loss: 0.5626
2025-06-04 13:36:06,640 INFO: Epoch 63, Batch 150, Loss: 0.5481
2025-06-04 13:36:08,120 INFO: Epoch 63, Batch 200, Loss: 0.6611
2025-06-04 13:36:09,644 INFO: Epoch 63, Batch 250, Loss: 0.5784
2025-06-04 13:36:10,543 INFO: Epoch 63, Train Loss: 0.6252
2025-06-04 13:36:10,604 INFO: Epoch 63, Eval Loss: 2.0334
2025-06-04 13:36:10,639 INFO: Epoch 64, Batch 0, Loss: 0.6183
2025-06-04 13:36:12,134 INFO: Epoch 64, Batch 50, Loss: 0.5670
2025-06-04 13:36:13,625 INFO: Epoch 64, Batch 100, Loss: 0.7659
2025-06-04 13:36:15,127 INFO: Epoch 64, Batch 150, Loss: 0.6345
2025-06-04 13:36:16,631 INFO: Epoch 64, Batch 200, Loss: 0.5959
2025-06-04 13:36:18,105 INFO: Epoch 64, Batch 250, Loss: 0.5950
2025-06-04 13:36:19,049 INFO: Epoch 64, Train Loss: 0.6218
2025-06-04 13:36:19,111 INFO: Epoch 64, Eval Loss: 2.0350
2025-06-04 13:36:19,141 INFO: Epoch 65, Batch 0, Loss: 0.5924
2025-06-04 13:36:20,634 INFO: Epoch 65, Batch 50, Loss: 0.6552
2025-06-04 13:36:22,133 INFO: Epoch 65, Batch 100, Loss: 0.6178
2025-06-04 13:36:23,625 INFO: Epoch 65, Batch 150, Loss: 0.5362
2025-06-04 13:36:25,119 INFO: Epoch 65, Batch 200, Loss: 0.6595
2025-06-04 13:36:26,614 INFO: Epoch 65, Batch 250, Loss: 0.6034
2025-06-04 13:36:27,537 INFO: Epoch 65, Train Loss: 0.6216
2025-06-04 13:36:27,599 INFO: Epoch 65, Eval Loss: 2.0345
2025-06-04 13:36:27,628 INFO: Epoch 66, Batch 0, Loss: 0.6375
2025-06-04 13:36:29,136 INFO: Epoch 66, Batch 50, Loss: 0.6093
2025-06-04 13:36:30,616 INFO: Epoch 66, Batch 100, Loss: 0.5633
2025-06-04 13:36:32,110 INFO: Epoch 66, Batch 150, Loss: 0.7065
2025-06-04 13:36:33,587 INFO: Epoch 66, Batch 200, Loss: 0.6707
2025-06-04 13:36:35,082 INFO: Epoch 66, Batch 250, Loss: 0.6497
2025-06-04 13:36:36,014 INFO: Epoch 66, Train Loss: 0.6222
2025-06-04 13:36:36,076 INFO: Epoch 66, Eval Loss: 2.0333
2025-06-04 13:36:36,103 INFO: Epoch 67, Batch 0, Loss: 0.5797
2025-06-04 13:36:37,588 INFO: Epoch 67, Batch 50, Loss: 0.6839
2025-06-04 13:36:39,071 INFO: Epoch 67, Batch 100, Loss: 0.5350
2025-06-04 13:36:40,566 INFO: Epoch 67, Batch 150, Loss: 0.5383
2025-06-04 13:36:42,059 INFO: Epoch 67, Batch 200, Loss: 0.6031
2025-06-04 13:36:43,583 INFO: Epoch 67, Batch 250, Loss: 0.5864
2025-06-04 13:36:44,491 INFO: Epoch 67, Train Loss: 0.6205
2025-06-04 13:36:44,552 INFO: Epoch 67, Eval Loss: 2.0342
2025-06-04 13:36:44,583 INFO: Epoch 68, Batch 0, Loss: 0.5868
2025-06-04 13:36:46,076 INFO: Epoch 68, Batch 50, Loss: 0.6541
2025-06-04 13:36:47,573 INFO: Epoch 68, Batch 100, Loss: 0.5861
2025-06-04 13:36:49,091 INFO: Epoch 68, Batch 150, Loss: 0.6385
2025-06-04 13:36:50,574 INFO: Epoch 68, Batch 200, Loss: 0.6011
2025-06-04 13:36:52,073 INFO: Epoch 68, Batch 250, Loss: 0.6327
2025-06-04 13:36:53,001 INFO: Epoch 68, Train Loss: 0.6189
2025-06-04 13:36:53,063 INFO: Epoch 68, Eval Loss: 2.0364
2025-06-04 13:36:53,090 INFO: Epoch 69, Batch 0, Loss: 0.6741
2025-06-04 13:36:54,604 INFO: Epoch 69, Batch 50, Loss: 0.5679
2025-06-04 13:36:56,096 INFO: Epoch 69, Batch 100, Loss: 0.5892
2025-06-04 13:36:57,600 INFO: Epoch 69, Batch 150, Loss: 0.6350
2025-06-04 13:36:59,072 INFO: Epoch 69, Batch 200, Loss: 0.5938
2025-06-04 13:37:00,532 INFO: Epoch 69, Batch 250, Loss: 0.6645
2025-06-04 13:37:01,455 INFO: Epoch 69, Train Loss: 0.6197
2025-06-04 13:37:01,516 INFO: Epoch 69, Eval Loss: 2.0353
2025-06-04 13:37:01,543 INFO: Epoch 70, Batch 0, Loss: 0.6203
2025-06-04 13:37:03,032 INFO: Epoch 70, Batch 50, Loss: 0.6009
2025-06-04 13:37:04,536 INFO: Epoch 70, Batch 100, Loss: 0.7400
2025-06-04 13:37:06,047 INFO: Epoch 70, Batch 150, Loss: 0.6785
2025-06-04 13:37:07,532 INFO: Epoch 70, Batch 200, Loss: 0.6093
2025-06-04 13:37:09,011 INFO: Epoch 70, Batch 250, Loss: 0.6153
2025-06-04 13:37:09,905 INFO: Epoch 70, Train Loss: 0.6209
2025-06-04 13:37:09,966 INFO: Epoch 70, Eval Loss: 2.0345
2025-06-04 13:37:09,994 INFO: Epoch 71, Batch 0, Loss: 0.5678
2025-06-04 13:37:11,519 INFO: Epoch 71, Batch 50, Loss: 0.5668
2025-06-04 13:37:12,997 INFO: Epoch 71, Batch 100, Loss: 0.5295
2025-06-04 13:37:14,494 INFO: Epoch 71, Batch 150, Loss: 0.4889
2025-06-04 13:37:15,992 INFO: Epoch 71, Batch 200, Loss: 0.7011
2025-06-04 13:37:17,481 INFO: Epoch 71, Batch 250, Loss: 0.5597
2025-06-04 13:37:18,423 INFO: Epoch 71, Train Loss: 0.6196
2025-06-04 13:37:18,484 INFO: Epoch 71, Eval Loss: 2.0324
2025-06-04 13:37:18,511 INFO: Epoch 72, Batch 0, Loss: 0.6409
2025-06-04 13:37:20,022 INFO: Epoch 72, Batch 50, Loss: 0.6551
2025-06-04 13:37:21,543 INFO: Epoch 72, Batch 100, Loss: 0.6000
2025-06-04 13:37:23,028 INFO: Epoch 72, Batch 150, Loss: 0.6077
2025-06-04 13:37:24,512 INFO: Epoch 72, Batch 200, Loss: 0.6985
2025-06-04 13:37:25,978 INFO: Epoch 72, Batch 250, Loss: 0.6709
2025-06-04 13:37:26,889 INFO: Epoch 72, Train Loss: 0.6184
2025-06-04 13:37:26,950 INFO: Epoch 72, Eval Loss: 2.0327
2025-06-04 13:37:26,978 INFO: Epoch 73, Batch 0, Loss: 0.5722
2025-06-04 13:37:28,464 INFO: Epoch 73, Batch 50, Loss: 0.6841
2025-06-04 13:37:29,957 INFO: Epoch 73, Batch 100, Loss: 0.6067
2025-06-04 13:37:31,466 INFO: Epoch 73, Batch 150, Loss: 0.6212
2025-06-04 13:37:32,961 INFO: Epoch 73, Batch 200, Loss: 0.5965
2025-06-04 13:37:34,488 INFO: Epoch 73, Batch 250, Loss: 0.6079
2025-06-04 13:37:35,398 INFO: Epoch 73, Train Loss: 0.6208
2025-06-04 13:37:35,460 INFO: Epoch 73, Eval Loss: 2.0330
2025-06-04 13:37:35,492 INFO: Epoch 74, Batch 0, Loss: 0.6597
2025-06-04 13:37:36,984 INFO: Epoch 74, Batch 50, Loss: 0.6083
2025-06-04 13:37:38,455 INFO: Epoch 74, Batch 100, Loss: 0.6448
2025-06-04 13:37:39,954 INFO: Epoch 74, Batch 150, Loss: 0.5798
2025-06-04 13:37:41,441 INFO: Epoch 74, Batch 200, Loss: 0.6632
2025-06-04 13:37:42,917 INFO: Epoch 74, Batch 250, Loss: 0.6297
2025-06-04 13:37:43,849 INFO: Epoch 74, Train Loss: 0.6203
2025-06-04 13:37:43,910 INFO: Epoch 74, Eval Loss: 2.0335
2025-06-04 13:37:43,943 INFO: Epoch 75, Batch 0, Loss: 0.6740
2025-06-04 13:37:45,451 INFO: Epoch 75, Batch 50, Loss: 0.5990
2025-06-04 13:37:46,975 INFO: Epoch 75, Batch 100, Loss: 0.5504
2025-06-04 13:37:48,444 INFO: Epoch 75, Batch 150, Loss: 0.6888
2025-06-04 13:37:49,936 INFO: Epoch 75, Batch 200, Loss: 0.6168
2025-06-04 13:37:51,422 INFO: Epoch 75, Batch 250, Loss: 0.5826
2025-06-04 13:37:52,344 INFO: Epoch 75, Train Loss: 0.6181
2025-06-04 13:37:52,404 INFO: Epoch 75, Eval Loss: 2.0341
2025-06-04 13:37:52,432 INFO: Epoch 76, Batch 0, Loss: 0.6257
2025-06-04 13:37:53,936 INFO: Epoch 76, Batch 50, Loss: 0.5689
2025-06-04 13:37:55,436 INFO: Epoch 76, Batch 100, Loss: 0.5921
2025-06-04 13:37:56,917 INFO: Epoch 76, Batch 150, Loss: 0.7241
2025-06-04 13:37:58,409 INFO: Epoch 76, Batch 200, Loss: 0.6624
2025-06-04 13:37:59,888 INFO: Epoch 76, Batch 250, Loss: 0.5988
2025-06-04 13:38:00,830 INFO: Epoch 76, Train Loss: 0.6169
2025-06-04 13:38:00,891 INFO: Epoch 76, Eval Loss: 2.0339
2025-06-04 13:38:00,918 INFO: Epoch 77, Batch 0, Loss: 0.5396
2025-06-04 13:38:02,400 INFO: Epoch 77, Batch 50, Loss: 0.6157
2025-06-04 13:38:03,913 INFO: Epoch 77, Batch 100, Loss: 0.5758
2025-06-04 13:38:05,403 INFO: Epoch 77, Batch 150, Loss: 0.6542
2025-06-04 13:38:06,887 INFO: Epoch 77, Batch 200, Loss: 0.6136
2025-06-04 13:38:08,368 INFO: Epoch 77, Batch 250, Loss: 0.5475
2025-06-04 13:38:09,303 INFO: Epoch 77, Train Loss: 0.6175
2025-06-04 13:38:09,363 INFO: Epoch 77, Eval Loss: 2.0343
2025-06-04 13:38:09,396 INFO: Epoch 78, Batch 0, Loss: 0.6932
2025-06-04 13:38:10,906 INFO: Epoch 78, Batch 50, Loss: 0.5979
2025-06-04 13:38:12,406 INFO: Epoch 78, Batch 100, Loss: 0.5594
2025-06-04 13:38:13,869 INFO: Epoch 78, Batch 150, Loss: 0.6057
2025-06-04 13:38:15,380 INFO: Epoch 78, Batch 200, Loss: 0.5685
2025-06-04 13:38:16,888 INFO: Epoch 78, Batch 250, Loss: 0.6054
2025-06-04 13:38:17,796 INFO: Epoch 78, Train Loss: 0.6169
2025-06-04 13:38:17,857 INFO: Epoch 78, Eval Loss: 2.0340
2025-06-04 13:38:17,886 INFO: Epoch 79, Batch 0, Loss: 0.6998
2025-06-04 13:38:19,381 INFO: Epoch 79, Batch 50, Loss: 0.6948
2025-06-04 13:38:20,873 INFO: Epoch 79, Batch 100, Loss: 0.6691
2025-06-04 13:38:22,355 INFO: Epoch 79, Batch 150, Loss: 0.5698
2025-06-04 13:38:23,841 INFO: Epoch 79, Batch 200, Loss: 0.6487
2025-06-04 13:38:25,314 INFO: Epoch 79, Batch 250, Loss: 0.5945
2025-06-04 13:38:26,256 INFO: Epoch 79, Train Loss: 0.6183
2025-06-04 13:38:26,317 INFO: Epoch 79, Eval Loss: 2.0341
2025-06-04 13:38:26,350 INFO: Epoch 80, Batch 0, Loss: 0.6355
2025-06-04 13:38:27,845 INFO: Epoch 80, Batch 50, Loss: 0.6895
2025-06-04 13:38:29,339 INFO: Epoch 80, Batch 100, Loss: 0.6217
2025-06-04 13:38:30,833 INFO: Epoch 80, Batch 150, Loss: 0.6107
2025-06-04 13:38:32,337 INFO: Epoch 80, Batch 200, Loss: 0.6537
2025-06-04 13:38:33,812 INFO: Epoch 80, Batch 250, Loss: 0.5737
2025-06-04 13:38:34,733 INFO: Epoch 80, Train Loss: 0.6191
2025-06-04 13:38:34,794 INFO: Epoch 80, Eval Loss: 2.0340
2025-06-04 13:38:34,822 INFO: Epoch 81, Batch 0, Loss: 0.5676
2025-06-04 13:38:36,323 INFO: Epoch 81, Batch 50, Loss: 0.6757
2025-06-04 13:38:37,836 INFO: Epoch 81, Batch 100, Loss: 0.6366
2025-06-04 13:38:39,328 INFO: Epoch 81, Batch 150, Loss: 0.7287
2025-06-04 13:38:40,819 INFO: Epoch 81, Batch 200, Loss: 0.6411
2025-06-04 13:38:42,302 INFO: Epoch 81, Batch 250, Loss: 0.6529
2025-06-04 13:38:43,217 INFO: Epoch 81, Train Loss: 0.6186
2025-06-04 13:38:43,278 INFO: Epoch 81, Eval Loss: 2.0340
2025-06-04 13:38:43,308 INFO: Epoch 82, Batch 0, Loss: 0.6224
2025-06-04 13:38:44,803 INFO: Epoch 82, Batch 50, Loss: 0.6493
2025-06-04 13:38:46,322 INFO: Epoch 82, Batch 100, Loss: 0.6208
2025-06-04 13:38:47,780 INFO: Epoch 82, Batch 150, Loss: 0.6259
2025-06-04 13:38:49,304 INFO: Epoch 82, Batch 200, Loss: 0.5386
2025-06-04 13:38:50,825 INFO: Epoch 82, Batch 250, Loss: 0.6573
2025-06-04 13:38:51,727 INFO: Epoch 82, Train Loss: 0.6186
2025-06-04 13:38:51,789 INFO: Epoch 82, Eval Loss: 2.0340
2025-06-04 13:38:51,819 INFO: Epoch 83, Batch 0, Loss: 0.7134
2025-06-04 13:38:53,294 INFO: Epoch 83, Batch 50, Loss: 0.6038
2025-06-04 13:38:54,797 INFO: Epoch 83, Batch 100, Loss: 0.6766
2025-06-04 13:38:56,317 INFO: Epoch 83, Batch 150, Loss: 0.6422
2025-06-04 13:38:57,813 INFO: Epoch 83, Batch 200, Loss: 0.6664
2025-06-04 13:38:59,297 INFO: Epoch 83, Batch 250, Loss: 0.6244
2025-06-04 13:39:00,214 INFO: Epoch 83, Train Loss: 0.6192
2025-06-04 13:39:00,276 INFO: Epoch 83, Eval Loss: 2.0339
2025-06-04 13:39:00,306 INFO: Epoch 84, Batch 0, Loss: 0.6433
2025-06-04 13:39:01,795 INFO: Epoch 84, Batch 50, Loss: 0.6384
2025-06-04 13:39:03,260 INFO: Epoch 84, Batch 100, Loss: 0.6679
2025-06-04 13:39:04,749 INFO: Epoch 84, Batch 150, Loss: 0.6982
2025-06-04 13:39:06,246 INFO: Epoch 84, Batch 200, Loss: 0.5875
2025-06-04 13:39:07,737 INFO: Epoch 84, Batch 250, Loss: 0.6172
2025-06-04 13:39:08,680 INFO: Epoch 84, Train Loss: 0.6180
2025-06-04 13:39:08,741 INFO: Epoch 84, Eval Loss: 2.0339
2025-06-04 13:39:08,772 INFO: Epoch 85, Batch 0, Loss: 0.5298
2025-06-04 13:39:10,282 INFO: Epoch 85, Batch 50, Loss: 0.6632
2025-06-04 13:39:11,805 INFO: Epoch 85, Batch 100, Loss: 0.6181
2025-06-04 13:39:13,326 INFO: Epoch 85, Batch 150, Loss: 0.5836
2025-06-04 13:39:14,820 INFO: Epoch 85, Batch 200, Loss: 0.5818
2025-06-04 13:39:16,311 INFO: Epoch 85, Batch 250, Loss: 0.5819
2025-06-04 13:39:17,201 INFO: Epoch 85, Train Loss: 0.6189
2025-06-04 13:39:17,263 INFO: Epoch 85, Eval Loss: 2.0339
2025-06-04 13:39:17,293 INFO: Epoch 86, Batch 0, Loss: 0.6482
2025-06-04 13:39:18,795 INFO: Epoch 86, Batch 50, Loss: 0.7188
2025-06-04 13:39:20,280 INFO: Epoch 86, Batch 100, Loss: 0.5662
2025-06-04 13:39:21,759 INFO: Epoch 86, Batch 150, Loss: 0.5554
2025-06-04 13:39:23,266 INFO: Epoch 86, Batch 200, Loss: 0.5867
2025-06-04 13:39:24,758 INFO: Epoch 86, Batch 250, Loss: 0.6507
2025-06-04 13:39:25,671 INFO: Epoch 86, Train Loss: 0.6180
2025-06-04 13:39:25,733 INFO: Epoch 86, Eval Loss: 2.0339
2025-06-04 13:39:25,766 INFO: Epoch 87, Batch 0, Loss: 0.7138
2025-06-04 13:39:27,252 INFO: Epoch 87, Batch 50, Loss: 0.6237
2025-06-04 13:39:28,734 INFO: Epoch 87, Batch 100, Loss: 0.6029
2025-06-04 13:39:30,255 INFO: Epoch 87, Batch 150, Loss: 0.5908
2025-06-04 13:39:31,732 INFO: Epoch 87, Batch 200, Loss: 0.5389
2025-06-04 13:39:33,243 INFO: Epoch 87, Batch 250, Loss: 0.6488
2025-06-04 13:39:34,148 INFO: Epoch 87, Train Loss: 0.6182
2025-06-04 13:39:34,210 INFO: Epoch 87, Eval Loss: 2.0339
2025-06-04 13:39:34,242 INFO: Epoch 88, Batch 0, Loss: 0.6571
2025-06-04 13:39:35,721 INFO: Epoch 88, Batch 50, Loss: 0.5720
2025-06-04 13:39:37,212 INFO: Epoch 88, Batch 100, Loss: 0.7003
2025-06-04 13:39:38,722 INFO: Epoch 88, Batch 150, Loss: 0.6454
2025-06-04 13:39:40,209 INFO: Epoch 88, Batch 200, Loss: 0.6445
2025-06-04 13:39:41,713 INFO: Epoch 88, Batch 250, Loss: 0.6447
2025-06-04 13:39:42,616 INFO: Epoch 88, Train Loss: 0.6196
2025-06-04 13:39:42,677 INFO: Epoch 88, Eval Loss: 2.0339
2025-06-04 13:39:42,707 INFO: Epoch 89, Batch 0, Loss: 0.6312
2025-06-04 13:39:44,222 INFO: Epoch 89, Batch 50, Loss: 0.5931
2025-06-04 13:39:45,732 INFO: Epoch 89, Batch 100, Loss: 0.6094
2025-06-04 13:39:47,230 INFO: Epoch 89, Batch 150, Loss: 0.5431
2025-06-04 13:39:48,697 INFO: Epoch 89, Batch 200, Loss: 0.5435
2025-06-04 13:39:50,179 INFO: Epoch 89, Batch 250, Loss: 0.4922
2025-06-04 13:39:51,121 INFO: Epoch 89, Train Loss: 0.6190
2025-06-04 13:39:51,182 INFO: Epoch 89, Eval Loss: 2.0340
2025-06-04 13:39:51,209 INFO: Epoch 90, Batch 0, Loss: 0.5934
2025-06-04 13:39:52,682 INFO: Epoch 90, Batch 50, Loss: 0.6461
2025-06-04 13:39:54,204 INFO: Epoch 90, Batch 100, Loss: 0.6030
2025-06-04 13:39:55,714 INFO: Epoch 90, Batch 150, Loss: 0.6281
2025-06-04 13:39:57,214 INFO: Epoch 90, Batch 200, Loss: 0.5939
2025-06-04 13:39:58,718 INFO: Epoch 90, Batch 250, Loss: 0.5384
2025-06-04 13:39:59,625 INFO: Epoch 90, Train Loss: 0.6178
2025-06-04 13:39:59,691 INFO: Epoch 90, Eval Loss: 2.0340
2025-06-04 13:39:59,719 INFO: Epoch 91, Batch 0, Loss: 0.6354
2025-06-04 13:40:01,233 INFO: Epoch 91, Batch 50, Loss: 0.6107
2025-06-04 13:40:02,753 INFO: Epoch 91, Batch 100, Loss: 0.6575
2025-06-04 13:40:04,253 INFO: Epoch 91, Batch 150, Loss: 0.6101
2025-06-04 13:40:05,730 INFO: Epoch 91, Batch 200, Loss: 0.6111
2025-06-04 13:40:07,223 INFO: Epoch 91, Batch 250, Loss: 0.5927
2025-06-04 13:40:08,137 INFO: Epoch 91, Train Loss: 0.6178
2025-06-04 13:40:08,198 INFO: Epoch 91, Eval Loss: 2.0340
2025-06-04 13:40:08,225 INFO: Epoch 92, Batch 0, Loss: 0.6110
2025-06-04 13:40:09,752 INFO: Epoch 92, Batch 50, Loss: 0.6156
2025-06-04 13:40:11,228 INFO: Epoch 92, Batch 100, Loss: 0.5350
2025-06-04 13:40:12,709 INFO: Epoch 92, Batch 150, Loss: 0.6091
2025-06-04 13:40:14,240 INFO: Epoch 92, Batch 200, Loss: 0.6343
2025-06-04 13:40:15,721 INFO: Epoch 92, Batch 250, Loss: 0.6222
2025-06-04 13:40:16,652 INFO: Epoch 92, Train Loss: 0.6190
2025-06-04 13:40:16,718 INFO: Epoch 92, Eval Loss: 2.0340
2025-06-04 13:40:16,750 INFO: Epoch 93, Batch 0, Loss: 0.7260
2025-06-04 13:40:18,250 INFO: Epoch 93, Batch 50, Loss: 0.6411
2025-06-04 13:40:19,735 INFO: Epoch 93, Batch 100, Loss: 0.6185
2025-06-04 13:40:21,236 INFO: Epoch 93, Batch 150, Loss: 0.5902
2025-06-04 13:40:22,723 INFO: Epoch 93, Batch 200, Loss: 0.5413
2025-06-04 13:40:24,227 INFO: Epoch 93, Batch 250, Loss: 0.6202
2025-06-04 13:40:25,162 INFO: Epoch 93, Train Loss: 0.6197
2025-06-04 13:40:25,224 INFO: Epoch 93, Eval Loss: 2.0340
2025-06-04 13:40:25,256 INFO: Epoch 94, Batch 0, Loss: 0.5616
2025-06-04 13:40:26,719 INFO: Epoch 94, Batch 50, Loss: 0.6240
2025-06-04 13:40:28,177 INFO: Epoch 94, Batch 100, Loss: 0.5714
2025-06-04 13:40:29,656 INFO: Epoch 94, Batch 150, Loss: 0.6590
2025-06-04 13:40:31,161 INFO: Epoch 94, Batch 200, Loss: 0.6296
2025-06-04 13:40:32,697 INFO: Epoch 94, Batch 250, Loss: 0.6105
2025-06-04 13:40:33,608 INFO: Epoch 94, Train Loss: 0.6186
2025-06-04 13:40:33,670 INFO: Epoch 94, Eval Loss: 2.0340
2025-06-04 13:40:33,699 INFO: Epoch 95, Batch 0, Loss: 0.6362
2025-06-04 13:40:35,203 INFO: Epoch 95, Batch 50, Loss: 0.6045
2025-06-04 13:40:36,719 INFO: Epoch 95, Batch 100, Loss: 0.5288
2025-06-04 13:40:38,188 INFO: Epoch 95, Batch 150, Loss: 0.6898
2025-06-04 13:40:39,683 INFO: Epoch 95, Batch 200, Loss: 0.5832
2025-06-04 13:40:41,177 INFO: Epoch 95, Batch 250, Loss: 0.6747
2025-06-04 13:40:42,102 INFO: Epoch 95, Train Loss: 0.6186
2025-06-04 13:40:42,164 INFO: Epoch 95, Eval Loss: 2.0341
2025-06-04 13:40:42,196 INFO: Epoch 96, Batch 0, Loss: 0.5673
2025-06-04 13:40:43,694 INFO: Epoch 96, Batch 50, Loss: 0.5943
2025-06-04 13:40:45,206 INFO: Epoch 96, Batch 100, Loss: 0.6949
2025-06-04 13:40:46,699 INFO: Epoch 96, Batch 150, Loss: 0.6755
2025-06-04 13:40:48,188 INFO: Epoch 96, Batch 200, Loss: 0.6079
2025-06-04 13:40:49,652 INFO: Epoch 96, Batch 250, Loss: 0.6741
2025-06-04 13:40:50,569 INFO: Epoch 96, Train Loss: 0.6192
2025-06-04 13:40:50,629 INFO: Epoch 96, Eval Loss: 2.0341
2025-06-04 13:40:50,655 INFO: Epoch 97, Batch 0, Loss: 0.5925
2025-06-04 13:40:52,146 INFO: Epoch 97, Batch 50, Loss: 0.5788
2025-06-04 13:40:53,629 INFO: Epoch 97, Batch 100, Loss: 0.6610
2025-06-04 13:40:55,133 INFO: Epoch 97, Batch 150, Loss: 0.6620
2025-06-04 13:40:56,634 INFO: Epoch 97, Batch 200, Loss: 0.5686
2025-06-04 13:40:58,127 INFO: Epoch 97, Batch 250, Loss: 0.6862
2025-06-04 13:40:59,032 INFO: Epoch 97, Train Loss: 0.6179
2025-06-04 13:40:59,092 INFO: Epoch 97, Eval Loss: 2.0341
2025-06-04 13:40:59,122 INFO: Epoch 98, Batch 0, Loss: 0.6144
2025-06-04 13:41:00,616 INFO: Epoch 98, Batch 50, Loss: 0.6147
2025-06-04 13:41:02,098 INFO: Epoch 98, Batch 100, Loss: 0.6733
2025-06-04 13:41:03,592 INFO: Epoch 98, Batch 150, Loss: 0.6400
2025-06-04 13:41:05,054 INFO: Epoch 98, Batch 200, Loss: 0.7042
2025-06-04 13:41:06,535 INFO: Epoch 98, Batch 250, Loss: 0.6326
2025-06-04 13:41:07,460 INFO: Epoch 98, Train Loss: 0.6205
2025-06-04 13:41:07,521 INFO: Epoch 98, Eval Loss: 2.0341
2025-06-04 13:41:07,548 INFO: Epoch 99, Batch 0, Loss: 0.5934
2025-06-04 13:41:09,031 INFO: Epoch 99, Batch 50, Loss: 0.6034
2025-06-04 13:41:10,525 INFO: Epoch 99, Batch 100, Loss: 0.6477
2025-06-04 13:41:12,038 INFO: Epoch 99, Batch 150, Loss: 0.5883
2025-06-04 13:41:13,513 INFO: Epoch 99, Batch 200, Loss: 0.6097
2025-06-04 13:41:14,981 INFO: Epoch 99, Batch 250, Loss: 0.6168
2025-06-04 13:41:15,900 INFO: Epoch 99, Train Loss: 0.6177
2025-06-04 13:41:15,961 INFO: Epoch 99, Eval Loss: 2.0342
